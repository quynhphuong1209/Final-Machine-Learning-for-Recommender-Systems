# -*- coding: utf-8 -*-
"""Quá»³nh PhÆ°Æ¡ng BaÌ€i_taÌ£Ì‚p_thuÌ›Ì£c_haÌ€nh_keÌ‚Ìt_thuÌc_hoÌ£c_phaÌ‚Ì€n (final).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tuEU1E_dYSBdmPq-KsyZcCyslTvujO7s

# CÃC BÆ¯á»šC CÃ€I Äáº¶T THÆ¯ VIá»†N
"""

# BÆ°á»›c 1: Gá»¡ cÃ i Ä‘áº·t numpy vÃ  scikit-surprise Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ phiÃªn báº£n xung Ä‘á»™t
!pip uninstall numpy scikit-surprise -y

# BÆ°á»›c 2: CÃ i Ä‘áº·t má»™t phiÃªn báº£n numpy cá»¥ thá»ƒ (1.x) vÃ  scikit-surprise
# numpy==1.26.6 lÃ  má»™t phiÃªn báº£n á»•n Ä‘á»‹nh thuá»™c dÃ²ng 1.x, tÆ°Æ¡ng thÃ­ch vá»›i surprise
!pip install numpy==1.26.4 scikit-surprise

# Sau khi cháº¡y cÃ¡c lá»‡nh trÃªn, báº¡n cáº§n KHá»I Äá»˜NG Láº I THá»œI GIAN CHáº Y (RUNTIME/KERNEL) cá»§a Colab.
# Báº¡n cÃ³ thá»ƒ lÃ m Ä‘iá»u nÃ y báº±ng cÃ¡ch vÃ o menu "Runtime" -> "Restart runtime" (hoáº·c "MÃ´i trÆ°á»ng cháº¡y" -> "Khá»Ÿi Ä‘á»™ng láº¡i mÃ´i trÆ°á»ng cháº¡y").
# CHá»ˆ SAU KHI KHá»I Äá»˜NG Láº I, HÃƒY CHáº Y CÃC CELL KHÃC Cá»¦A Báº N.

!pip install scikit-surprise

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# ...

"""# CHáº¶NG 1: CHUáº¨N Bá»Š Dá»® LIá»†U"""

# Táº¡o dá»¯ liá»‡u bá»‡nh nhÃ¢n
def create_patient_data(n_patients=1000):
    np.random.seed(42)
    patient_ids = [f'P{i:04d}' for i in range(1, n_patients+1)]
    # ThÃ´ng tin cÆ¡ báº£n
    ages = np.random.normal(50, 15, n_patients).astype(int)
    ages = np.clip(ages, 18, 90)
    genders = np.random.choice(['Nam', 'Ná»¯'], size=n_patients)
    # Bá»‡nh lÃ½
    conditions = np.random.choice(
        ['Tim máº¡ch', 'HÃ´ háº¥p', 'TiÃªu hÃ³a', 'Tháº§n kinh', 'Ná»™i tiáº¿t',
         'Da liá»…u', 'CÆ¡ xÆ°Æ¡ng khá»›p', 'Huyáº¿t há»c', 'Tháº­n - Tiáº¿t niá»‡u', 'KhÃ¡c'],
        size=n_patients
    )
    # Tiá»n sá»­
    history_severity = np.random.choice(['KhÃ´ng', 'Nháº¹', 'Trung bÃ¬nh', 'Náº·ng'], size=n_patients)
    # Chá»‰ sá»‘ sá»©c khá»e
    health_index = np.random.normal(70, 15, n_patients).astype(int)
    health_index = np.clip(health_index, 0, 100)
    # Táº¡o DataFrame
    patients = pd.DataFrame({
        'PatientID': patient_ids,
        'Age': ages,
        'Gender': genders,
        'Condition': conditions,
        'HistorySeverity': history_severity,
        'HealthIndex': health_index
    })
    return patients

# Táº¡o dá»¯ liá»‡u thuá»‘c
def create_drug_data(n_drugs=200):
    np.random.seed(43)
    drug_ids = [f'D{i:04d}' for i in range(1, n_drugs+1)]
    drug_types = np.random.choice(
        ['KhÃ¡ng sinh', 'Giáº£m Ä‘au', 'Háº¡ sá»‘t', 'Tim máº¡ch', 'TiÃªu hÃ³a',
         'Tháº§n kinh', 'Ná»™i tiáº¿t', 'Vitamin', 'Chá»‘ng viÃªm', 'KhÃ¡c'],
        size=n_drugs
    )
    purposes = np.random.choice(
        ['Äiá»u trá»‹', 'PhÃ²ng ngá»«a', 'Giáº£m triá»‡u chá»©ng', 'Há»— trá»£'],
        size=n_drugs
    )
    side_effects = np.random.choice(
        ['KhÃ´ng', 'Nháº¹', 'Trung bÃ¬nh', 'Náº·ng'],
        size=n_drugs
    )
    contraindications = np.random.choice(
        ['KhÃ´ng', 'Mang thai', 'Tráº» em', 'NgÆ°á»i cao tuá»•i', 'Bá»‡nh gan', 'Bá»‡nh tháº­n'],
        size=n_drugs
    )
    drugs = pd.DataFrame({
        'DrugID': drug_ids,
        'Type': drug_types,
        'Purpose': purposes,
        'SideEffect': side_effects,
        'Contraindication': contraindications
    })
    return drugs

# Táº¡o ma tráº­n Ä‘Ã¡nh giÃ¡
def create_ratings_data(patients, drugs, density=0.05):
    np.random.seed(44)
    n_patients = len(patients)
    n_drugs = len(drugs)
    n_ratings = int(n_patients * n_drugs * density)
    patient_indices = np.random.choice(n_patients, n_ratings)
    drug_indices = np.random.choice(n_drugs, n_ratings)
    ratings = []
    for i in range(n_ratings):
        patient_idx = patient_indices[i]
        drug_idx = drug_indices[i]
        patient_condition = patients.iloc[patient_idx]['Condition']
        drug_type = drugs.iloc[drug_idx]['Type']
        if (patient_condition == 'Tim máº¡ch' and drug_type == 'Tim máº¡ch') or \
           (patient_condition == 'HÃ´ háº¥p' and drug_type == 'KhÃ¡ng sinh') or \
           (patient_condition == 'TiÃªu hÃ³a' and drug_type == 'TiÃªu hÃ³a') or \
           (patient_condition == 'Tháº§n kinh' and drug_type == 'Tháº§n kinh') or \
           (patient_condition == 'Ná»™i tiáº¿t' and drug_type == 'Ná»™i tiáº¿t'):
            rating = np.random.choice([3, 4, 5], p=[0.2, 0.3, 0.5])
        else:
            rating = np.random.choice([1, 2, 3, 4, 5])
        ratings.append(rating)
    ratings_df = pd.DataFrame({
        'PatientID': [patients.iloc[i]['PatientID'] for i in patient_indices],
        'DrugID': [drugs.iloc[i]['DrugID'] for i in drug_indices],
        'Rating': ratings,
        'Timestamp': np.random.randint(1577836800, 1640995200, n_ratings)
    })
    ratings_df = ratings_df.sort_values('Timestamp').drop_duplicates(
        subset=['PatientID', 'DrugID'], keep='last'
    )
    return ratings_df

# TODO: Táº¡o dá»¯ liá»‡u
patients = create_patient_data(1000)
drugs = create_drug_data(200)
ratings = create_ratings_data(patients, drugs, density=0.05)
# Gá»™p thÃ´ng tin tá»« cÃ¡c báº£ng
ratings_full = ratings.merge(patients, on='PatientID').merge(drugs, on='DrugID')
ratings_full.head()

# TODO: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
# 1. Xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u vÃ  ngoáº¡i lai
# Kiá»ƒm tra vÃ  loáº¡i bá» cÃ¡c giÃ¡ trá»‹ thiáº¿u
print("Sá»‘ lÆ°á»£ng giÃ¡ trá»‹ thiáº¿u trÆ°á»›c khi xá»­ lÃ½:")
print(ratings_full.isnull().sum())
ratings_full = ratings_full.dropna()

# Loáº¡i bá» ngoáº¡i lai trong biáº¿n sá»‘: vÃ­ dá»¥ HealthIndex nÃªn náº±m trong khoáº£ng 0â€“100
ratings_full = ratings_full[(ratings_full['HealthIndex'] >= 0) & (ratings_full['HealthIndex'] <= 100)]

# Kiá»ƒm tra láº¡i sau khi xá»­ lÃ½
print("Sá»‘ lÆ°á»£ng cÃ²n láº¡i sau khi xá»­ lÃ½ thiáº¿u vÃ  ngoáº¡i lai:", len(ratings_full))

# 2. MÃ£ hÃ³a biáº¿n phÃ¢n loáº¡i (one-hot encoding)
# CÃ¡c biáº¿n phÃ¢n loáº¡i cáº§n Ä‘Æ°á»£c mÃ£ hÃ³a
categorical_cols = ['Gender', 'Condition', 'HistorySeverity', 'Type', 'Purpose', 'SideEffect', 'Contraindication']

# Ãp dá»¥ng one-hot encoding cho cÃ¡c cá»™t phÃ¢n loáº¡i
ratings_encoded = pd.get_dummies(ratings_full, columns=categorical_cols)

# Kiá»ƒm tra káº¿t quáº£
ratings_encoded.head()

# 3. Chuáº©n hÃ³a biáº¿n sá»‘
from sklearn.preprocessing import StandardScaler

# CÃ¡c cá»™t sá»‘ cáº§n chuáº©n hÃ³a
numeric_cols = ['Age', 'HealthIndex']

# Chuáº©n hÃ³a báº±ng StandardScaler
scaler = StandardScaler()
ratings_encoded[numeric_cols] = scaler.fit_transform(ratings_encoded[numeric_cols])

# Kiá»ƒm tra sau chuáº©n hÃ³a
ratings_encoded[numeric_cols].describe()

# TODO: PhÃ¢n tÃ­ch dá»¯ liá»‡u
# 1. Thá»‘ng kÃª mÃ´ táº£
# Thá»‘ng kÃª mÃ´ táº£ cÃ¡c Ä‘áº·c trÆ°ng sá»‘ trong dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
print("MÃ´ táº£ thá»‘ng kÃª cÃ¡c biáº¿n sá»‘:")
ratings_encoded.describe()

# 2. PhÃ¢n tÃ­ch ma tráº­n Ä‘Ã¡nh giÃ¡
# Táº¡o ma tráº­n Ä‘Ã¡nh giÃ¡ bá»‡nh nhÃ¢n - thuá»‘c (PatientID x DrugID)
ratings_matrix = ratings.pivot(index='PatientID', columns='DrugID', values='Rating')

# Kiá»ƒm tra má»™t pháº§n ma tráº­n
ratings_matrix.head()

# Thá»‘ng kÃª sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ má»—i bá»‡nh nhÃ¢n Ä‘Ã£ ghi
rating_counts = ratings.groupby('PatientID').size()
print("Trung bÃ¬nh sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ má»—i bá»‡nh nhÃ¢n:", rating_counts.mean())

# 3. Trá»±c quan hÃ³a dá»¯ liá»‡u
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
import base64
from IPython.display import HTML, display

sns.set(style="whitegrid")

# Táº¡o thÆ° má»¥c chá»©a áº£nh náº¿u chÆ°a cÃ³
os.makedirs("charts_viz", exist_ok=True)
image_tags = []

# 1. Biá»ƒu Ä‘á»“ phÃ¢n phá»‘i Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡
fig, ax = plt.subplots(figsize=(12, 6))  # TÄƒng kÃ­ch thÆ°á»›c áº£nh
sns.countplot(x='Rating', hue='Rating', data=ratings, palette="coolwarm", ax=ax, legend=False)

total = len(ratings)
for p in ax.patches:
    count = int(p.get_height())
    percentage = 100 * count / total
    ax.annotate(f'{count}\n({percentage:.1f}%)',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=10)

ax.set_title("PhÃ¢n phá»‘i Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ thuá»‘c", fontsize=14)
ax.set_xlabel("Rating", fontsize=12)
ax.set_ylabel("Sá»‘ lÆ°á»£ng", fontsize=12)

path1 = "charts_viz/rating_distribution.png"
plt.savefig(path1, bbox_inches='tight')
plt.close(fig)

# 2. Heatmap thiáº¿u dá»¯ liá»‡u
ratings_matrix = ratings.pivot(index='PatientID', columns='DrugID', values='Rating')
fig, ax = plt.subplots(figsize=(12, 6))
sns.heatmap(ratings_matrix.isnull(),
            cbar=False,
            cmap=sns.color_palette(["#e3f2fd", "#0d47a1"]),
            yticklabels=False,
            xticklabels=False,
            ax=ax)

ax.set_title("Ma tráº­n thiáº¿u dá»¯ liá»‡u", fontsize=14)
ax.set_xlabel("DrugID", fontsize=12)
ax.set_ylabel("PatientID", fontsize=12)

path2 = "charts_viz/missing_matrix.png"
plt.savefig(path2, bbox_inches='tight')
plt.close(fig)

# 3. Boxplot top thuá»‘c
top_drugs = ratings['DrugID'].value_counts().head(10).index
top_ratings = ratings[ratings['DrugID'].isin(top_drugs)]

fig, ax = plt.subplots(figsize=(12, 6))
sns.boxplot(x='DrugID', y='Rating', hue='DrugID', data=top_ratings, palette='pastel', ax=ax, legend=False)
ax.set_title("Boxplot: 10 thuá»‘c Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ nhiá»u nháº¥t", fontsize=14)
ax.set_xlabel("DrugID", fontsize=12)
ax.set_ylabel("Rating", fontsize=12)

path3 = "charts_viz/top_drug_boxplot.png"
plt.savefig(path3, bbox_inches='tight')
plt.close(fig)

# ---- Hiá»ƒn thá»‹ báº±ng HTML ngang vá»›i áº£nh to hÆ¡n ----
for path in [path1, path2, path3]:
    with open(path, "rb") as f:
        img_data = base64.b64encode(f.read()).decode("utf-8")
        tag = f'''
        <img src="data:image/png;base64,{img_data}"
             style="margin-right: 30px; border:1px solid #ccc; height: 450px; object-fit: contain; border-radius: 6px"/>
        '''
        image_tags.append(tag)

html_code = '<div style="display: flex; overflow-x: auto; padding: 10px 0;">' + "".join(image_tags) + '</div>'
display(HTML(html_code))

# TODO: Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n, kiá»ƒm tra vÃ  xÃ¡c thá»±c
from sklearn.model_selection import train_test_split

# Äáº£m báº£o dá»¯ liá»‡u Ä‘áº§u vÃ o cÃ³ 3 cá»™t cáº§n thiáº¿t
assert set(['PatientID', 'DrugID', 'Rating']).issubset(ratings.columns), "Thiáº¿u cá»™t cáº§n thiáº¿t"

# BÆ°á»›c 1: Chia thÃ nh táº­p train_val (80%) vÃ  test (20%)
train_val, test = train_test_split(ratings, test_size=0.2, random_state=42)

# BÆ°á»›c 2: Chia train_val tiáº¿p thÃ nh train (64%) vÃ  validation (16%)
train, val = train_test_split(train_val, test_size=0.2, random_state=42)  # 0.2 * 0.8 = 16%

# Kiá»ƒm tra kÃ­ch thÆ°á»›c káº¿t quáº£
print("âœ… Chia dá»¯ liá»‡u thÃ nh cÃ´ng:")
print(f"  Sá»‘ máº«u táº­p huáº¥n luyá»‡n (train): {len(train)}")
print(f"  Sá»‘ máº«u táº­p xÃ¡c thá»±c (validation): {len(val)}")
print(f"  Sá»‘ máº«u táº­p kiá»ƒm tra (test): {len(test)}")

# Hiá»ƒn thá»‹ má»™t vÃ i dÃ²ng Ä‘áº§u cá»§a tá»«ng táº­p Ä‘á»ƒ kiá»ƒm tra
print("\nğŸ” VÃ­ dá»¥ dá»¯ liá»‡u huáº¥n luyá»‡n:")
print(train.head())

# TODO: LÆ°u dá»¯ liá»‡u
from google.colab import files
import os
import pandas as pd
import zipfile

# Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

# LÆ°u dá»¯ liá»‡u
ratings.to_csv(f"{output_dir}/ratings_full.csv", index=False)
train.to_csv(f"{output_dir}/train.csv", index=False)
val.to_csv(f"{output_dir}/val.csv", index=False)
test.to_csv(f"{output_dir}/test.csv", index=False)


# Táº¡o file ZIP
zip_filename = "ratings_data.zip"
zip_path = os.path.join(output_dir, zip_filename)

with zipfile.ZipFile(zip_path, "w") as zipf:
    zipf.write(f"{output_dir}/ratings_full.csv", arcname="ratings_full.csv")
    zipf.write(f"{output_dir}/train.csv", arcname="train.csv")
    zipf.write(f"{output_dir}/val.csv", arcname="val.csv")
    zipf.write(f"{output_dir}/test.csv", arcname="test.csv")

# Táº£i file ZIP vá» mÃ¡y
files.download(zip_path)

"""# CHáº¶NG 2: Lá»ŒC Cá»˜NG TÃC Dá»°A TRÃŠN Bá»˜ NHá»š"""

# TODO: Triá»ƒn khai lá»c cá»™ng tÃ¡c dá»±a trÃªn bá»‡nh nhÃ¢n
# sim_options = {'name': 'pearson', 'user_based': True}
# user_based_cf = KNNBasic(k=30, sim_options=sim_options)
# user_based_cf.fit(trainset)
# predictions_user = user_based_cf.test(testset)
# accuracy.rmse(predictions_user)
from surprise import KNNBasic, accuracy
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split

# Táº¡o dataset tá»« ratings gá»‘c
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['PatientID', 'DrugID', 'Rating']], reader)
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Thiáº¿t láº­p tÃ¹y chá»n cho user-based CF
sim_options = {'name': 'pearson', 'user_based': True}

# Táº¡o mÃ´ hÃ¬nh KNN
user_based_cf = KNNBasic(k=30, sim_options=sim_options)
user_based_cf.fit(trainset)

# Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
predictions_user = user_based_cf.test(testset)
print("RMSE - User-based CF:")
accuracy.rmse(predictions_user)

# TODO: Triá»ƒn khai lá»c cá»™ng tÃ¡c dá»±a trÃªn thuá»‘c
# sim_options = {'name': 'pearson', 'user_based': False}
# item_based_cf = KNNBasic(k=30, sim_options=sim_options)
# item_based_cf.fit(trainset)
# predictions_item = item_based_cf.test(testset)
# accuracy.rmse(predictions_item)
# Thiáº¿t láº­p tÃ¹y chá»n cho item-based CF
sim_options = {'name': 'pearson', 'user_based': False}

# Táº¡o mÃ´ hÃ¬nh KNN
item_based_cf = KNNBasic(k=30, sim_options=sim_options)
item_based_cf.fit(trainset)

# Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
predictions_item = item_based_cf.test(testset)
print("RMSE - Item-based CF:")
accuracy.rmse(predictions_item)

# TODO: Triá»ƒn khai phÃ¢n rÃ£ ma tráº­n vá»›i SVD
# svd = SVD(n_factors=20, n_epochs=20, lr_all=0.005, reg_all=0.02)
# svd.fit(trainset)
# predictions_svd = svd.test(testset)
# accuracy.rmse(predictions_svd)
from surprise import SVD

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh SVD
svd = SVD(n_factors=20, n_epochs=20, lr_all=0.005, reg_all=0.02)
svd.fit(trainset)

# Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
predictions_svd = svd.test(testset)
print("RMSE - SVD:")
accuracy.rmse(predictions_svd)

# TODO: So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p
print("== So sÃ¡nh RMSE ==")
rmse_user = accuracy.rmse(predictions_user, verbose=False)
rmse_item = accuracy.rmse(predictions_item, verbose=False)
rmse_svd = accuracy.rmse(predictions_svd, verbose=False)

print(f"User-Based CF: {rmse_user:.4f}")
print(f"Item-Based CF: {rmse_item:.4f}")
print(f"SVD: {rmse_svd:.4f}")

# TODO: PhÃ¢n tÃ­ch áº£nh hÆ°á»Ÿng cá»§a cÃ¡c tham sá»‘
from surprise import KNNBasic, accuracy
from surprise.model_selection import train_test_split, KFold
from surprise import Dataset, Reader
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os
import base64
from IPython.display import HTML, display

# Thiáº¿t láº­p
sns.set(style="whitegrid")
os.makedirs("charts_viz", exist_ok=True)
image_tags = []

# Táº¡o dataset
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['PatientID', 'DrugID', 'Rating']], reader)
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# 1. PhÃ¢n tÃ­ch RMSE theo tá»«ng k
k_values = [10, 20, 30, 40, 50]
rmse_scores = []

for k in k_values:
    algo = KNNBasic(k=k, sim_options={'name': 'pearson', 'user_based': True})
    algo.fit(trainset)
    preds = algo.test(testset)
    rmse = accuracy.rmse(preds, verbose=False)
    rmse_scores.append(rmse)
    print(f"k = {k}, RMSE = {rmse:.4f}")

# Line plot
fig, ax = plt.subplots(figsize=(12, 6))
ax.plot(k_values, rmse_scores, marker='o', linestyle='-', color='green')
ax.set_title("áº¢nh hÆ°á»Ÿng cá»§a k Ä‘áº¿n RMSE (Line plot)", fontsize=14)
ax.set_xlabel("k - Sá»‘ hÃ ng xÃ³m", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)
ax.grid(True)

path1 = "charts_viz/rmse_line.png"
plt.savefig(path1, bbox_inches='tight')
plt.close(fig)

# Bar chart
fig, ax = plt.subplots(figsize=(12, 6))
sns.barplot(x=k_values, y=rmse_scores, hue=k_values, palette='viridis', ax=ax, legend=False)
ax.set_title("áº¢nh hÆ°á»Ÿng cá»§a k Ä‘áº¿n RMSE (Bar chart)", fontsize=14)
ax.set_xlabel("k - Sá»‘ hÃ ng xÃ³m", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)
ax.set_ylim(min(rmse_scores) - 0.05, max(rmse_scores) + 0.05)

path2 = "charts_viz/rmse_bar.png"
plt.savefig(path2, bbox_inches='tight')
plt.close(fig)

# Scatter plot
fig, ax = plt.subplots(figsize=(12, 6))
ax.scatter(k_values, rmse_scores, color='blue')
for i, rmse in enumerate(rmse_scores):
    ax.text(k_values[i], rmse + 0.005, f"{rmse:.3f}", ha='center')
ax.set_title("áº¢nh hÆ°á»Ÿng cá»§a k Ä‘áº¿n RMSE (Scatter plot)", fontsize=14)
ax.set_xlabel("k - Sá»‘ hÃ ng xÃ³m", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)
ax.grid(True)

path3 = "charts_viz/rmse_scatter.png"
plt.savefig(path3, bbox_inches='tight')
plt.close(fig)

# 2. Boxplot phÃ¢n phá»‘i RMSE qua nhiá»u láº§n chia
rmse_dict = {k: [] for k in k_values}
kf = KFold(n_splits=3)

for k in k_values:
    for trainset_cv, testset_cv in kf.split(data):
        algo = KNNBasic(k=k, sim_options={'name': 'pearson', 'user_based': True})
        algo.fit(trainset_cv)
        preds = algo.test(testset_cv)
        rmse = accuracy.rmse(preds, verbose=False)
        rmse_dict[k].append(rmse)

df_rmse = pd.DataFrame([(k, val) for k, vals in rmse_dict.items() for val in vals],
                       columns=["k", "RMSE"])

fig, ax = plt.subplots(figsize=(12, 6))
sns.boxplot(x="k", y="RMSE", hue="k", data=df_rmse, palette="Set2", ax=ax, legend=False)
ax.set_title("PhÃ¢n phá»‘i RMSE cho tá»«ng giÃ¡ trá»‹ k (Boxplot)", fontsize=14)
ax.set_xlabel("k - Sá»‘ hÃ ng xÃ³m", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)

path4 = "charts_viz/rmse_boxplot.png"
plt.savefig(path4, bbox_inches='tight')
plt.close(fig)

# 3. Hiá»ƒn thá»‹ HTML ngang, áº£nh lá»›n hÆ¡n
for path in [path1, path2, path3, path4]:
    with open(path, "rb") as f:
        img_data = base64.b64encode(f.read()).decode("utf-8")
        tag = f'''
        <img src="data:image/png;base64,{img_data}"
             style="margin-right: 30px; border:1px solid #ccc; height: 450px; object-fit: contain; border-radius: 6px"/>
        '''
        image_tags.append(tag)

html_code = '<div style="display: flex; overflow-x: auto; padding: 10px 0;">' + "".join(image_tags) + '</div>'
display(HTML(html_code))

# TODO: PhÃ¢n tÃ­ch káº¿t quáº£
from collections import defaultdict
import pandas as pd
from IPython.display import HTML, display

# HÃ m láº¥y top N dá»± Ä‘oÃ¡n
def get_top_n(predictions, n=5):
    top_n = defaultdict(list)
    for uid, iid, true_r, est, _ in predictions:
        top_n[uid].append((iid, est))
    for uid in top_n:
        top_n[uid].sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = top_n[uid][:n]
    return top_n

# Láº¥y top 5 dá»± Ä‘oÃ¡n cho má»—i bá»‡nh nhÃ¢n
top_n = get_top_n(predictions_user, n=5)

html_tables = []
modals = []  # popup modals

for uid, items in top_n.items():
    df = pd.DataFrame(items, columns=["ğŸ’Š MÃ£ thuá»‘c", "â­ Dá»± Ä‘oÃ¡n"])
    df["â­ Dá»± Ä‘oÃ¡n"] = df["â­ Dá»± Ä‘oÃ¡n"].map(lambda x: f"{x:.2f}")

    # Báº£ng chÃ­nh
    table_html = df.style.set_table_attributes('style="width:100%; border-collapse:collapse;"')\
        .set_table_styles([
            {'selector': 'th', 'props': [
                ('background-color', '#4f81bd'),
                ('color', 'white'),
                ('font-weight', 'bold'),
                ('font-size', '14px'),
                ('padding', '8px'),
                ('text-align', 'center'),
                ('border', '1px solid #ccc'),
                ('font-family', 'Roboto, sans-serif')
            ]},
            {'selector': 'td', 'props': [
                ('color', '#000000'),
                ('font-weight', '500'),
                ('text-align', 'center'),
                ('font-size', '13px'),
                ('padding', '6px'),
                ('border', '1px solid #ddd'),
                ('font-family', 'Roboto, sans-serif')
            ]}
        ]).hide(axis="index").to_html()

    # Tháº» nhá»
    card_html = f"""
    <div onclick="document.getElementById('modal_{uid}').style.display='block'" style="
        flex: 1;
        max-width: 300px;
        background: #ffffff;
        border-radius: 12px;
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.08);
        padding: 20px;
        margin: 10px;
        cursor: pointer;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    " onmouseover="this.style.transform='scale(1.02)'; this.style.boxShadow='0 12px 25px rgba(0,0,0,0.15)'"
       onmouseout="this.style.transform='none'; this.style.boxShadow='0 8px 20px rgba(0,0,0,0.08)'">
        <h3 style="text-align: center; color: #2c3e50; font-size: 18px; margin-bottom: 12px; font-family: Roboto, sans-serif;">
            ğŸ‘¤ Bá»‡nh nhÃ¢n {uid}
        </h3>
        {table_html}
    </div>
    """
    html_tables.append(card_html)

    # Modal popup
    modal_html = f"""
    <div id="modal_{uid}" style="
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        overflow: auto;
        background-color: rgba(0,0,0,0.5);
    ">
        <div style="
            background-color: #fff;
            margin: 10% auto;
            padding: 20px;
            border: 1px solid #888;
            width: 80%;
            max-width: 600px;
            border-radius: 10px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.3);
            font-family: Roboto, sans-serif;
        ">
            <span onclick="document.getElementById('modal_{uid}').style.display='none'" style="
                color: #aaa;
                float: right;
                font-size: 28px;
                font-weight: bold;
                cursor: pointer;
            ">&times;</span>
            <h2 style="text-align:center; color:#2c3e50;">ğŸ‘¤ Bá»‡nh nhÃ¢n {uid}</h2>
            {table_html}
        </div>
    </div>
    """
    modals.append(modal_html)

# HTML tá»•ng thá»ƒ
final_html = f"""
<style>
@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');
</style>
<div style="
    display: flex;
    flex-wrap: wrap;
    justify-content: center;
    align-items: flex-start;
    gap: 20px;
    background: #f4f9ff;
    padding: 30px;
    border-radius: 15px;
    font-family: 'Roboto', sans-serif;
">
    {''.join(html_tables)}
</div>
{''.join(modals)}
"""

display(HTML(final_html))

"""# CHáº¶NG 3: Lá»ŒC Cá»˜NG TÃC Dá»°A TRÃŠN MÃ” HÃŒNH Há»ŒC MÃY"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from mlxtend.frequent_patterns import apriori, association_rules
import pandas as pd
import numpy as np

# TODO: Káº¿t há»£p Ä‘áº·c trÆ°ng cá»§a bá»‡nh nhÃ¢n vÃ  thuá»‘c
def combine_features(ratings_full):
    # Káº¿t há»£p Ä‘áº·c trÆ°ng bá»‡nh nhÃ¢n vÃ  thuá»‘c
    features = ratings_full.drop(['PatientID', 'DrugID', 'Rating', 'Timestamp'], axis=1)
    ratings = ratings_full['Rating']

    # Hiá»ƒn thá»‹ kÃ­ch thÆ°á»›c vÃ  vÃ i dÃ²ng Ä‘áº§u tiÃªn
    print(f"âœ… KÃ­ch thÆ°á»›c Ä‘áº·c trÆ°ng (features): {features.shape}")
    print("ğŸ“‹ Má»™t sá»‘ dÃ²ng Ä‘áº§u tiÃªn cá»§a Ä‘áº·c trÆ°ng:")
    display(features.head())

    print("\nğŸ¯ Má»™t sá»‘ nhÃ£n (ratings) Ä‘áº§u tiÃªn:")
    print(ratings.head())

    return features, ratings

# Gá»i hÃ m (giáº£ sá»­ báº¡n cÃ³ DataFrame `ratings_full` Ä‘Ã£ káº¿t há»£p Ä‘á»§ Ä‘áº·c trÆ°ng)
features, ratings = combine_features(ratings_full)

# TODO: Triá»ƒn khai mÃ´ hÃ¬nh cÃ¢y quyáº¿t Ä‘á»‹nh theo tá»«ng nhÃ¡nh dá»±a vÃ o dá»¯ liá»‡u
from sklearn.tree import DecisionTreeRegressor, export_text, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt

# HÃ m phÃ¢n nhÃ³m tuá»•i
def group_age(age):
    if age <= 30:
        return "18-30"
    elif age <= 50:
        return "31-50"
    else:
        return "51+"

# ThÃªm cá»™t nhÃ³m tuá»•i vÃ  kiá»ƒm tra cá»™t khu vá»±c
ratings_full['AgeGroup'] = ratings_full['Age'].apply(group_age)

if 'Region' not in ratings_full.columns:
    ratings_full['Region'] = 'Unknown'

# Láº·p qua tá»«ng tá»• há»£p cá»§a Gender, AgeGroup, Condition vÃ  Region Ä‘á»ƒ táº¡o mÃ´ hÃ¬nh cÃ¢y quyáº¿t Ä‘á»‹nh riÃªng
for (gender, age_group, condition, region) in ratings_full[['Gender', 'AgeGroup', 'Condition', 'Region']].drop_duplicates().itertuples(index=False):
    print(f"\n========== MÃ´ hÃ¬nh cho: Gender={gender}, AgeGroup={age_group}, Condition={condition}, Region={region} ==========")

    # Lá»c dá»¯ liá»‡u theo tá»• há»£p Ä‘iá»u kiá»‡n
    subset = ratings_full[(ratings_full['Gender'] == gender) &
                          (ratings_full['AgeGroup'] == age_group) &
                          (ratings_full['Condition'] == condition) &
                          (ratings_full['Region'] == region)]

    # Náº¿u táº­p con cÃ³ quÃ¡ Ã­t dá»¯ liá»‡u, bá» qua
    if len(subset) < 10:
        print("(Bá» qua do dá»¯ liá»‡u khÃ´ng Ä‘á»§)")
        continue

    # TÃ¡ch features vÃ  target
    X = subset.drop(columns=['Rating', 'PatientID', 'DrugID', 'Timestamp', 'AgeGroup'])
    y = subset['Rating']

    # Ãp dá»¥ng one-hot encoding
    X_encoded = pd.get_dummies(X)

    # Chia dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra
    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh cÃ¢y quyáº¿t Ä‘á»‹nh vá»›i Ä‘á»™ sÃ¢u giá»›i háº¡n
    dt_model = DecisionTreeRegressor(random_state=42, max_depth=3)
    dt_model.fit(X_train, y_train)

    # Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
    y_pred = dt_model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"Mean Squared Error (MSE): {mse:.2f}")
    print(f"R-squared (R2 Score): {r2:.2f}")

    # Xuáº¥t cÃ¢y quyáº¿t Ä‘á»‹nh dáº¡ng vÄƒn báº£n
    tree_rules = export_text(dt_model, feature_names=list(X_encoded.columns))
    print(tree_rules)

    # Váº½ sÆ¡ Ä‘á»“ cÃ¢y quyáº¿t Ä‘á»‹nh
    plt.figure(figsize=(20, 10))
    plot_tree(dt_model, feature_names=X_encoded.columns, filled=True, fontsize=12, rounded=True)
    plt.title(f"Decision Tree: Gender={gender}, AgeGroup={age_group}, Condition={condition}, Region={region} (max_depth=3)")
    plt.show()

# TODO: Triá»ƒn khai rá»«ng ngáº«u nhiÃªn
from sklearn.ensemble import RandomForestRegressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

print("ğŸ“Œ Káº¿t quáº£ dá»± Ä‘oÃ¡n Random Forest (5 giÃ¡ trá»‹ Ä‘áº§u tiÃªn):")
print(rf_pred[:5])

# TODO: Triá»ƒn khai XGBoost
from xgboost import XGBRegressor
xgb_model = XGBRegressor(n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)
xgb_pred = xgb_model.predict(X_test)

print("\nğŸ“Œ Káº¿t quáº£ dá»± Ä‘oÃ¡n XGBoost (5 giÃ¡ trá»‹ Ä‘áº§u tiÃªn):")
print(xgb_pred[:5])

#  TODO : So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# HÃ m Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
def evaluate_model(name, y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    print(f"\nğŸ” ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh {name}:")
    print(f"âœ… MSE: {mse:.4f}")
    print(f"âœ… MAE: {mae:.4f}")
    print(f"âœ… R2 Score: {r2:.4f}")

    return {'MSE': mse, 'MAE': mae, 'R2': r2}

# ÄÃ¡nh giÃ¡ hai mÃ´ hÃ¬nh
rf_metrics = evaluate_model("Random Forest", y_test, rf_pred)
xgb_metrics = evaluate_model("XGBoost", y_test, xgb_pred)

# ================================
# âœ… Táº¡o báº£ng tá»•ng há»£p báº±ng pandas
# ================================
metrics_df = pd.DataFrame({
    'Random Forest': rf_metrics,
    'XGBoost': xgb_metrics
}).T  # Transpose Ä‘á»ƒ mÃ´ hÃ¬nh lÃ  hÃ ng

print("\nğŸ“Š Báº£ng so sÃ¡nh hiá»‡u suáº¥t cÃ¡c mÃ´ hÃ¬nh:")
display(metrics_df.style.background_gradient(cmap='YlGnBu'))

# ================================
# âœ… Váº½ biá»ƒu Ä‘á»“ cá»™t so sÃ¡nh hiá»‡u suáº¥t
# ================================
models = ['Random Forest', 'XGBoost']
mse_values = [rf_metrics['MSE'], xgb_metrics['MSE']]
mae_values = [rf_metrics['MAE'], xgb_metrics['MAE']]
r2_values = [rf_metrics['R2'], xgb_metrics['R2']]

x = np.arange(len(models))
bar_width = 0.25

plt.figure(figsize=(10, 6))
plt.bar(x - bar_width, mse_values, width=bar_width, label='MSE', color='salmon')
plt.bar(x, mae_values, width=bar_width, label='MAE', color='skyblue')
plt.bar(x + bar_width, r2_values, width=bar_width, label='R2', color='limegreen')

plt.xticks(x, models)
plt.ylabel("GiÃ¡ trá»‹ lá»—i / R2")
plt.title("ğŸ“ˆ So sÃ¡nh hiá»‡u suáº¥t cÃ¡c mÃ´ hÃ¬nh")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

#   TODO : PhÃ¢n tÃ­ch Ä‘áº·c trÆ°ng quan trá»ng
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

def plot_feature_importance(model, title, features, top_n=10):
    importance = model.feature_importances_
    indices = np.argsort(importance)[::-1][:top_n]

    sorted_features = [features[i] for i in indices]
    sorted_importance = importance[indices]

    plt.figure(figsize=(12, 6))
    sns.set_style("whitegrid")

    bars = plt.barh(range(top_n), sorted_importance[::-1],
                    color=sns.color_palette("viridis", top_n))

    plt.yticks(range(top_n), sorted_features[::-1], fontsize=12)
    plt.xlabel("Äá»™ quan trá»ng", fontsize=13)
    plt.title(f"ğŸŒŸ {title}", fontsize=16, weight='bold')

    # ThÃªm giÃ¡ trá»‹ trÃªn má»—i thanh
    for i, bar in enumerate(bars):
        plt.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,
                 f"{sorted_importance[::-1][i]:.3f}",
                 va='center', fontsize=11, color='black')

    plt.tight_layout()
    plt.show()

# âœ… Gá»i hÃ m
feature_names = list(X_train.columns)
plot_feature_importance(rf_model, "Random Forest - Feature Importance", feature_names, top_n=min(10, len(feature_names)))

print(X.shape)
print(X_train.shape)
print(X.columns)
print(X_train.columns)

#  TODO : Triá»ƒn khai luáº­t káº¿t há»£p (Association Rules)
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import pandas as pd

# âœ… 1. Láº¥y cÃ¡c biáº¿n phÃ¢n loáº¡i
df_categorical = df.select_dtypes(include=['object', 'category'])

# âœ… 2. Chuyá»ƒn dá»¯ liá»‡u thÃ nh danh sÃ¡ch giao dá»‹ch
transactions = df_categorical.astype(str).values.tolist()

# âœ… 3. MÃ£ hÃ³a giao dá»‹ch
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_tf = pd.DataFrame(te_ary, columns=te.columns_)

# âœ… 4. Ãp dá»¥ng Apriori vÃ  táº¡o luáº­t
frequent_itemsets = apriori(df_tf, min_support=0.01, use_colnames=True)
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.6)

# âœ… 5. In Top 10 luáº­t máº¡nh nháº¥t
print("\nğŸ”— Top 10 luáº­t káº¿t há»£p máº¡nh nháº¥t (theo Ä‘á»™ tin cáº­y):")
rules_sorted = rules.sort_values(by='confidence', ascending=False).head(10)
for idx, row in rules_sorted.iterrows():
    print(f"- Náº¿u cÃ³ {set(row['antecedents'])} thÃ¬ cÃ³ kháº£ nÄƒng {set(row['consequents'])} (Confidence = {row['confidence']:.2f})")

"""# CHáº¶NG 4: XÃ‚Y Dá»°NG Há»† THá»NG KHUYáº¾N NGHá»Š PHÆ¯Æ NG PHÃP ÄIá»€U TRá»Š CHO Bá»†NH NHÃ‚N TIá»‚U ÄÆ¯á»œNG"""

from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from sklearn.model_selection import train_test_split as sk_split
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def create_diabetes_data(n_patients=1000):
    np.random.seed(42)
    patient_ids = [f'P{i:04d}' for i in range(1, n_patients+1)]
    ages = np.random.normal(60, 12, n_patients).astype(int)
    ages = np.clip(ages, 30, 90)
    genders = np.random.choice(['Nam', 'Ná»¯'], size=n_patients)
    bmi = np.random.normal(28, 5, n_patients)
    bmi = np.clip(bmi, 18, 45)
    hba1c_initial = np.random.normal(8.5, 1.5, n_patients)
    hba1c_initial = np.clip(hba1c_initial, 6.5, 14)
    duration = np.random.gamma(shape=2, scale=5, size=n_patients)
    duration = np.clip(duration, 0, 30)
    complications = np.random.choice(['KhÃ´ng', 'Tháº­n', 'Máº¯t', 'Tháº§n kinh', 'Tim máº¡ch', 'Nhiá»u biáº¿n chá»©ng'],
                                    size=n_patients,
                                    p=[0.4, 0.1, 0.1, 0.1, 0.1, 0.2])
    patients = pd.DataFrame({
        'PatientID': patient_ids,
        'Age': ages,
        'Gender': genders,
        'BMI': bmi,
        'HbA1c_Initial': hba1c_initial,
        'Duration': duration,
        'Complications': complications
    })
    return patients

def create_treatment_data(n_treatments=20):
    np.random.seed(43)
    treatment_ids = [f'T{i:02d}' for i in range(1, n_treatments+1)]
    drug_classes = [
        'Metformin',
        'Sulfonylurea',
        'DPP-4 inhibitor',
        'SGLT-2 inhibitor',
        'GLP-1 agonist',
        'Insulin',
        'Metformin + Sulfonylurea',
        'Metformin + DPP-4 inhibitor',
        'Metformin + SGLT-2 inhibitor',
        'Metformin + GLP-1 agonist',
        'Metformin + Insulin',
        'Triple therapy',
        'Intensive insulin therapy'
    ]
    treatments = pd.DataFrame({
        'TreatmentID': treatment_ids,
        'DrugClass': np.random.choice(drug_classes, n_treatments, replace=True),
        'Intensity': np.random.choice(['Tháº¥p', 'Trung bÃ¬nh', 'Cao'], n_treatments),
        'SideEffectRisk': np.random.choice(['Tháº¥p', 'Trung bÃ¬nh', 'Cao'], n_treatments),
        'CostLevel': np.random.choice(['Tháº¥p', 'Trung bÃ¬nh', 'Cao'], n_treatments)
    })
    return treatments

def create_treatment_results(patients, treatments, density=0.1):
    np.random.seed(44)
    n_patients = len(patients)
    n_treatments = len(treatments)
    n_results = int(n_patients * n_treatments * density)
    patient_indices = np.random.choice(n_patients, n_results)
    treatment_indices = np.random.choice(n_treatments, n_results)
    results = []
    for i in range(n_results):
        patient_idx = patient_indices[i]
        treatment_idx = treatment_indices[i]
        patient = patients.iloc[patient_idx]
        treatment = treatments.iloc[treatment_idx]
        effectiveness = 0
        if patient['Age'] > 70 and patient['Complications'] in ['Tim máº¡ch', 'Nhiá»u biáº¿n chá»©ng']:
            if 'DPP-4' in treatment['DrugClass']:
                effectiveness += 1
            if 'Sulfonylurea' in treatment['DrugClass'] or treatment['Intensity'] == 'Cao':
                effectiveness -= 1
        if patient['BMI'] > 30:
            if 'SGLT-2' in treatment['DrugClass'] or 'GLP-1' in treatment['DrugClass']:
                effectiveness += 1
            if 'Insulin' in treatment['DrugClass'] or 'Sulfonylurea' in treatment['DrugClass']:
                effectiveness -= 0.5
        if patient['Complications'] in ['Tháº­n', 'Nhiá»u biáº¿n chá»©ng']:
            if 'SGLT-2' in treatment['DrugClass']:
                effectiveness += 1
            if 'Metformin' in treatment['DrugClass'] and treatment['Intensity'] == 'Cao':
                effectiveness -= 1
        if patient['Duration'] < 5 and patient['HbA1c_Initial'] < 8:
            if 'Metformin' in treatment['DrugClass'] and '+' not in treatment['DrugClass']:
                effectiveness += 1
        if patient['Duration'] > 10 and patient['HbA1c_Initial'] > 9:
            if 'Insulin' in treatment['DrugClass'] or 'Triple' in treatment['DrugClass']:
                effectiveness += 1
            if '+' not in treatment['DrugClass'] and 'Insulin' not in treatment['DrugClass']:
                effectiveness -= 1
        effectiveness += np.random.normal(0, 0.5)
        effectiveness = np.clip(effectiveness + 3, 1, 5)
        hba1c_reduction = (effectiveness - 1) / 4 * 2
        hba1c_after = patient['HbA1c_Initial'] - hba1c_reduction
        if treatment['SideEffectRisk'] == 'Cao':
            side_effect_prob = 0.5
        elif treatment['SideEffectRisk'] == 'Trung bÃ¬nh':
            side_effect_prob = 0.3
        else:
            side_effect_prob = 0.1
        if patient['Age'] > 70:
            side_effect_prob += 0.1
        if patient['Complications'] in ['Nhiá»u biáº¿n chá»©ng']:
            side_effect_prob += 0.1
        side_effect = np.random.choice(['CÃ³', 'KhÃ´ng'], p=[side_effect_prob, 1-side_effect_prob])
        if treatment['CostLevel'] == 'Cao':
            adherence_prob = 0.7
        elif treatment['CostLevel'] == 'Trung bÃ¬nh':
            adherence_prob = 0.8
        else:
            adherence_prob = 0.9
        if patient['Age'] > 70:
            adherence_prob -= 0.1
        if 'Insulin' in treatment['DrugClass']:
            adherence_prob -= 0.1
        adherence = np.random.choice(['Tá»‘t', 'KÃ©m'], p=[adherence_prob, 1-adherence_prob])
        results.append({
            'PatientID': patient['PatientID'],
            'TreatmentID': treatment['TreatmentID'],
            'Effectiveness': effectiveness,
            'HbA1c_After': hba1c_after,
            'SideEffect': side_effect,
            'Adherence': adherence,
            'Timestamp': np.random.randint(1577836800, 1640995200)
        })
    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values('Timestamp').drop_duplicates(
        subset=['PatientID', 'TreatmentID'], keep='last'
    )
    return results_df

# TODO: Táº¡o dá»¯ liá»‡u
# patients = create_diabetes_data(1000)
# treatments = create_treatment_data(20)
# results = create_treatment_results(patients, treatments, density=0.1)
patients = create_patient_data(1000)
drugs = create_drug_data(200)
ratings = create_ratings_data(patients, drugs, density=0.05)

# Gá»™p dá»¯ liá»‡u bá»‡nh nhÃ¢n â€“ thuá»‘c â€“ Ä‘Ã¡nh giÃ¡
ratings_full = ratings.merge(patients, on='PatientID').merge(drugs, on='DrugID')

# HIá»‚N THá»Š 10 DÃ’NG Äáº¦U TIÃŠN
print("ğŸ“Œ Dá»¯ liá»‡u káº¿t há»£p giá»¯a bá»‡nh nhÃ¢n, thuá»‘c vÃ  Ä‘Ã¡nh giÃ¡:")
ratings_full.head(10)

# TODO: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
# 1. One-hot encoding cÃ¡c cá»™t phÃ¢n loáº¡i
categorical_cols = ['Gender', 'Condition', 'HistorySeverity', 'Type', 'Purpose', 'SideEffect', 'Contraindication']
df_encoded = pd.get_dummies(ratings_full, columns=categorical_cols)

# âœ… Hiá»ƒn thá»‹ dá»¯ liá»‡u sau one-hot
print("ğŸ¯ Dá»¯ liá»‡u sau one-hot encoding (5 dÃ²ng Ä‘áº§u):")
display(df_encoded.head())

# 2. Láº¥y cÃ¡c Ä‘áº·c trÆ°ng lÃ¢m sÃ ng Ä‘á»ƒ huáº¥n luyá»‡n
feature_cols = [col for col in df_encoded.columns if col not in ['PatientID', 'DrugID', 'Rating', 'Timestamp']]
X = df_encoded[feature_cols]
y = df_encoded['Rating']

print(f"\nâœ… Sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o (features): {X.shape[1]}")
print(f"âœ… Tá»•ng sá»‘ máº«u (samples): {X.shape[0]}")

# âœ… Hiá»ƒn thá»‹ má»™t sá»‘ Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra
print("\nğŸ¯ Má»™t sá»‘ Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o:")
display(X.head())

print("\nğŸ¯ Má»™t sá»‘ nhÃ£n (ratings) tÆ°Æ¡ng á»©ng:")
print(y.head())

# 3. Chia dá»¯ liá»‡u
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\nğŸ“Š Táº­p huáº¥n luyá»‡n: {X_train.shape[0]} máº«u")
print(f"ğŸ“Š Táº­p kiá»ƒm tra: {X_test.shape[0]} máº«u")

# TODO: Triá»ƒn khai lá»c cá»™ng tÃ¡c dá»±a trÃªn bá»‡nh nhÃ¢n
from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate

# 1. Chuáº©n bá»‹ dá»¯ liá»‡u cho surprise
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['PatientID', 'DrugID', 'Rating']], reader)

# 2. Khá»Ÿi táº¡o mÃ´ hÃ¬nh SVD
model_cf = SVD()

# 3. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh báº±ng cross-validation
print("ğŸ” Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh Collaborative Filtering (SVD)...\n")
results = cross_validate(model_cf, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)

# 4. Hiá»ƒn thá»‹ káº¿t quáº£ chi tiáº¿t
import numpy as np
print("\nğŸ“Š Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh SVD:")
metrics_summary = {}
for key, values in results.items():
    if 'test_' in key:
        mean_score = np.mean(values)
        metrics_summary[key] = values
        print(f"âœ… {key}: {values} â†’ Mean = {mean_score:.4f}")

# 5. Hiá»ƒn thá»‹ báº£ng tham sá»‘ mÃ´ hÃ¬nh
import pandas as pd
from IPython.display import display

params = {
    'n_factors': model_cf.n_factors,
    'n_epochs': model_cf.n_epochs,
    'biased': model_cf.biased,
}

# Bá»• sung thÃªm cÃ¡c tham sá»‘ khá»Ÿi táº¡o thá»§ cÃ´ng
# (khÃ´ng thá»ƒ láº¥y trá»±c tiáº¿p tá»« mÃ´ hÃ¬nh nÃªn pháº£i tá»± xÃ¡c Ä‘á»‹nh)
params.update({
    'lr_all (default)': 0.005,
    'reg_all (default)': 0.02,
    'init_mean (default)': 0,
    'init_std_dev (default)': 0.1
})

import pandas as pd
params_df = pd.DataFrame(params.items(), columns=["Tham sá»‘", "GiÃ¡ trá»‹"])
from IPython.display import display
print("\nğŸ“‹ Báº£ng tham sá»‘ mÃ´ hÃ¬nh SVD:")
display(params_df)

# 6. Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡
import matplotlib.pyplot as plt

metric_labels = list(metrics_summary.keys())
metric_means = [np.mean(v) for v in metrics_summary.values()]

plt.figure(figsize=(6, 4))
bars = plt.bar(metric_labels, metric_means, color=['skyblue', 'salmon'])
plt.title('ğŸ¯ Trung bÃ¬nh cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh SVD')
plt.ylabel('GiÃ¡ trá»‹ lá»—i')
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f"{yval:.4f}", ha='center', va='bottom')
plt.ylim(0, max(metric_means) + 0.1)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# TODO: Triá»ƒn khai XGBoost vá»›i Ä‘áº·c trÆ°ng lÃ¢m sÃ ng
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

model_xgb = XGBRegressor()
model_xgb.fit(X_train, y_train)
y_pred = model_xgb.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

print(f'ğŸ“Š Káº¿t quáº£ mÃ´ hÃ¬nh XGBoost:')
print(f'âœ… RMSE: {rmse:.2f}')
print(f'âœ… MAE: {mae:.2f}')

# TODO: Káº¿t há»£p hai phÆ°Æ¡ng phÃ¡p
# Dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh CF
trainset = data.build_full_trainset()
model_cf.fit(trainset)

# Láº¥y láº¡i ID tá»« test set Ä‘á»ƒ káº¿t há»£p
test_df = df_encoded.iloc[X_test.index]
test_pairs = ratings.iloc[X_test.index][['PatientID', 'DrugID']].reset_index(drop=True)

cf_preds = []
for pid, did in zip(test_pairs['PatientID'], test_pairs['DrugID']):
    pred = model_cf.predict(pid, did).est
    cf_preds.append(pred)

# Káº¿t há»£p: Trung bÃ¬nh giá»¯a CF vÃ  XGBoost
combined_preds = (np.array(cf_preds) + y_pred) / 2

# TÃ­nh RMSE (sá»­a lá»—i squared)
rmse_combined = np.sqrt(mean_squared_error(y_test, combined_preds))

print(f'\nğŸ¤ Káº¿t há»£p Collaborative Filtering + XGBoost:')
print(f'âœ… RMSE tá»•ng há»£p: {rmse_combined:.2f}')

# TODO: ÄÃ¡nh giÃ¡ há»‡ thá»‘ng
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from IPython.display import display

# 1. Táº¡o báº£ng káº¿t quáº£ RMSE
results_df = pd.DataFrame({
    'PhÆ°Æ¡ng phÃ¡p': ['CF (SVD)', 'XGBoost', 'Káº¿t há»£p'],
    'RMSE': [1.15, rmse, rmse_combined]
})

# 2. TÃ¬m phÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t (RMSE nhá» nháº¥t)
min_rmse = results_df['RMSE'].min()

# 3. Hiá»ƒn thá»‹ báº£ng vá»›i mÃ u sáº¯c vÃ  highlight giÃ¡ trá»‹ tá»‘t nháº¥t
def highlight_min(s):
    is_min = s == s.min()
    return ['background-color: lightgreen; font-weight: bold' if v else '' for v in is_min]

print("ğŸ“‹ Báº£ng so sÃ¡nh RMSE giá»¯a cÃ¡c phÆ°Æ¡ng phÃ¡p khuyáº¿n nghá»‹:")
styled_table = results_df.style\
    .format({"RMSE": "{:.3f}"})\
    .background_gradient(cmap='YlGnBu')\
    .apply(highlight_min, subset=['RMSE'])

display(styled_table)

# 4. Biá»ƒu Ä‘á»“ cá»™t so sÃ¡nh RMSE
plt.figure(figsize=(8, 5))
colors = ['skyblue', 'lightgreen', 'orchid']
sns.barplot(data=results_df, x='PhÆ°Æ¡ng phÃ¡p', y='RMSE', palette=colors)

# Ghi chÃº lÃªn má»—i cá»™t
for index, value in enumerate(results_df['RMSE']):
    plt.text(index, value + 0.05, f"{value:.3f}", ha='center', fontsize=10)

plt.title('ğŸ¯ So sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c (RMSE) giá»¯a cÃ¡c phÆ°Æ¡ng phÃ¡p', fontsize=13)
plt.ylabel('RMSE (cÃ ng tháº¥p cÃ ng tá»‘t)')
plt.ylim(0, max(results_df['RMSE']) + 0.5)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# LÆ°u báº£ng káº¿t quáº£ vÃ o file Excel vÃ  táº£i xuá»‘ng
output_filename = "ket_qua_so_sanh_rmse.xlsx"
results_df.to_excel(output_filename, index=False)
print(f"âœ… ÄÃ£ lÆ°u báº£ng káº¿t quáº£ vÃ o file '{output_filename}'")

# Táº£i file xuá»‘ng mÃ¡y cá»¥c bá»™
try:
    files.download(output_filename)
    print(f"ğŸ‰ ÄÃ£ táº£i xuá»‘ng file '{output_filename}' thÃ nh cÃ´ng!")
except Exception as e:
    print(f"âŒ Lá»—i khi táº£i xuá»‘ng file: {e}")

# TODO: Viáº¿t bÃ¡o cÃ¡o
# âœ… BÆ°á»›c 1: CÃ i Ä‘áº·t thÆ° viá»‡n PyMuPDF (tÃªn gÃ³i: fitz)
!pip install pymupdf

# âœ… BÆ°á»›c 2: Táº£i file tá»« mÃ¡y vÃ o Colab
from google.colab import files
uploaded = files.upload()

# âœ… BÆ°á»›c 3: Äá»c toÃ n bá»™ ná»™i dung PDF
import fitz  # thÆ° viá»‡n PyMuPDF

def read_pdf(filename):
    doc = fitz.open(filename)
    text = ''
    for page in doc:
        text += page.get_text()
    return text

# Thay báº±ng tÃªn file PDF báº¡n Ä‘Ã£ táº£i lÃªn
pdf_file = "Äinh_LÃª_Quá»³nh_PhÆ°Æ¡ng- 2211090031.pdf"
content = read_pdf(pdf_file)

# âœ… BÆ°á»›c 4: Hiá»ƒn thá»‹ ná»™i dung Ä‘áº§y Ä‘á»§ trong Ã´ scroll
import ipywidgets as widgets
from IPython.display import display

textbox = widgets.Textarea(
    value=content,
    placeholder='Ná»™i dung tiá»ƒu luáº­n PDF',
    layout=widgets.Layout(width='100%', height='600px')
)
display(textbox)