# -*- coding: utf-8 -*-
"""Quỳnh Phương Bài_tập_thực_hành_kết_thúc_học_phần (final).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tuEU1E_dYSBdmPq-KsyZcCyslTvujO7s

# CÁC BƯỚC CÀI ĐẶT THƯ VIỆN
"""

# Bước 1: Gỡ cài đặt numpy và scikit-surprise để đảm bảo không có phiên bản xung đột
!pip uninstall numpy scikit-surprise -y

# Bước 2: Cài đặt một phiên bản numpy cụ thể (1.x) và scikit-surprise
# numpy==1.26.6 là một phiên bản ổn định thuộc dòng 1.x, tương thích với surprise
!pip install numpy==1.26.4 scikit-surprise

# Sau khi chạy các lệnh trên, bạn cần KHỞI ĐỘNG LẠI THỜI GIAN CHẠY (RUNTIME/KERNEL) của Colab.
# Bạn có thể làm điều này bằng cách vào menu "Runtime" -> "Restart runtime" (hoặc "Môi trường chạy" -> "Khởi động lại môi trường chạy").
# CHỈ SAU KHI KHỞI ĐỘNG LẠI, HÃY CHẠY CÁC CELL KHÁC CỦA BẠN.

!pip install scikit-surprise

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# ...

"""# CHẶNG 1: CHUẨN BỊ DỮ LIỆU"""

# Tạo dữ liệu bệnh nhân
def create_patient_data(n_patients=1000):
    np.random.seed(42)
    patient_ids = [f'P{i:04d}' for i in range(1, n_patients+1)]
    # Thông tin cơ bản
    ages = np.random.normal(50, 15, n_patients).astype(int)
    ages = np.clip(ages, 18, 90)
    genders = np.random.choice(['Nam', 'Nữ'], size=n_patients)
    # Bệnh lý
    conditions = np.random.choice(
        ['Tim mạch', 'Hô hấp', 'Tiêu hóa', 'Thần kinh', 'Nội tiết',
         'Da liễu', 'Cơ xương khớp', 'Huyết học', 'Thận - Tiết niệu', 'Khác'],
        size=n_patients
    )
    # Tiền sử
    history_severity = np.random.choice(['Không', 'Nhẹ', 'Trung bình', 'Nặng'], size=n_patients)
    # Chỉ số sức khỏe
    health_index = np.random.normal(70, 15, n_patients).astype(int)
    health_index = np.clip(health_index, 0, 100)
    # Tạo DataFrame
    patients = pd.DataFrame({
        'PatientID': patient_ids,
        'Age': ages,
        'Gender': genders,
        'Condition': conditions,
        'HistorySeverity': history_severity,
        'HealthIndex': health_index
    })
    return patients

# Tạo dữ liệu thuốc
def create_drug_data(n_drugs=200):
    np.random.seed(43)
    drug_ids = [f'D{i:04d}' for i in range(1, n_drugs+1)]
    drug_types = np.random.choice(
        ['Kháng sinh', 'Giảm đau', 'Hạ sốt', 'Tim mạch', 'Tiêu hóa',
         'Thần kinh', 'Nội tiết', 'Vitamin', 'Chống viêm', 'Khác'],
        size=n_drugs
    )
    purposes = np.random.choice(
        ['Điều trị', 'Phòng ngừa', 'Giảm triệu chứng', 'Hỗ trợ'],
        size=n_drugs
    )
    side_effects = np.random.choice(
        ['Không', 'Nhẹ', 'Trung bình', 'Nặng'],
        size=n_drugs
    )
    contraindications = np.random.choice(
        ['Không', 'Mang thai', 'Trẻ em', 'Người cao tuổi', 'Bệnh gan', 'Bệnh thận'],
        size=n_drugs
    )
    drugs = pd.DataFrame({
        'DrugID': drug_ids,
        'Type': drug_types,
        'Purpose': purposes,
        'SideEffect': side_effects,
        'Contraindication': contraindications
    })
    return drugs

# Tạo ma trận đánh giá
def create_ratings_data(patients, drugs, density=0.05):
    np.random.seed(44)
    n_patients = len(patients)
    n_drugs = len(drugs)
    n_ratings = int(n_patients * n_drugs * density)
    patient_indices = np.random.choice(n_patients, n_ratings)
    drug_indices = np.random.choice(n_drugs, n_ratings)
    ratings = []
    for i in range(n_ratings):
        patient_idx = patient_indices[i]
        drug_idx = drug_indices[i]
        patient_condition = patients.iloc[patient_idx]['Condition']
        drug_type = drugs.iloc[drug_idx]['Type']
        if (patient_condition == 'Tim mạch' and drug_type == 'Tim mạch') or \
           (patient_condition == 'Hô hấp' and drug_type == 'Kháng sinh') or \
           (patient_condition == 'Tiêu hóa' and drug_type == 'Tiêu hóa') or \
           (patient_condition == 'Thần kinh' and drug_type == 'Thần kinh') or \
           (patient_condition == 'Nội tiết' and drug_type == 'Nội tiết'):
            rating = np.random.choice([3, 4, 5], p=[0.2, 0.3, 0.5])
        else:
            rating = np.random.choice([1, 2, 3, 4, 5])
        ratings.append(rating)
    ratings_df = pd.DataFrame({
        'PatientID': [patients.iloc[i]['PatientID'] for i in patient_indices],
        'DrugID': [drugs.iloc[i]['DrugID'] for i in drug_indices],
        'Rating': ratings,
        'Timestamp': np.random.randint(1577836800, 1640995200, n_ratings)
    })
    ratings_df = ratings_df.sort_values('Timestamp').drop_duplicates(
        subset=['PatientID', 'DrugID'], keep='last'
    )
    return ratings_df

# TODO: Tạo dữ liệu
patients = create_patient_data(1000)
drugs = create_drug_data(200)
ratings = create_ratings_data(patients, drugs, density=0.05)
# Gộp thông tin từ các bảng
ratings_full = ratings.merge(patients, on='PatientID').merge(drugs, on='DrugID')
ratings_full.head()

# TODO: Tiền xử lý dữ liệu
# 1. Xử lý giá trị thiếu và ngoại lai
# Kiểm tra và loại bỏ các giá trị thiếu
print("Số lượng giá trị thiếu trước khi xử lý:")
print(ratings_full.isnull().sum())
ratings_full = ratings_full.dropna()

# Loại bỏ ngoại lai trong biến số: ví dụ HealthIndex nên nằm trong khoảng 0–100
ratings_full = ratings_full[(ratings_full['HealthIndex'] >= 0) & (ratings_full['HealthIndex'] <= 100)]

# Kiểm tra lại sau khi xử lý
print("Số lượng còn lại sau khi xử lý thiếu và ngoại lai:", len(ratings_full))

# 2. Mã hóa biến phân loại (one-hot encoding)
# Các biến phân loại cần được mã hóa
categorical_cols = ['Gender', 'Condition', 'HistorySeverity', 'Type', 'Purpose', 'SideEffect', 'Contraindication']

# Áp dụng one-hot encoding cho các cột phân loại
ratings_encoded = pd.get_dummies(ratings_full, columns=categorical_cols)

# Kiểm tra kết quả
ratings_encoded.head()

# 3. Chuẩn hóa biến số
from sklearn.preprocessing import StandardScaler

# Các cột số cần chuẩn hóa
numeric_cols = ['Age', 'HealthIndex']

# Chuẩn hóa bằng StandardScaler
scaler = StandardScaler()
ratings_encoded[numeric_cols] = scaler.fit_transform(ratings_encoded[numeric_cols])

# Kiểm tra sau chuẩn hóa
ratings_encoded[numeric_cols].describe()

# TODO: Phân tích dữ liệu
# 1. Thống kê mô tả
# Thống kê mô tả các đặc trưng số trong dữ liệu đã xử lý
print("Mô tả thống kê các biến số:")
ratings_encoded.describe()

# 2. Phân tích ma trận đánh giá
# Tạo ma trận đánh giá bệnh nhân - thuốc (PatientID x DrugID)
ratings_matrix = ratings.pivot(index='PatientID', columns='DrugID', values='Rating')

# Kiểm tra một phần ma trận
ratings_matrix.head()

# Thống kê số lượng đánh giá mỗi bệnh nhân đã ghi
rating_counts = ratings.groupby('PatientID').size()
print("Trung bình số lượng đánh giá mỗi bệnh nhân:", rating_counts.mean())

# 3. Trực quan hóa dữ liệu
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
import base64
from IPython.display import HTML, display

sns.set(style="whitegrid")

# Tạo thư mục chứa ảnh nếu chưa có
os.makedirs("charts_viz", exist_ok=True)
image_tags = []

# 1. Biểu đồ phân phối điểm đánh giá
fig, ax = plt.subplots(figsize=(12, 6))  # Tăng kích thước ảnh
sns.countplot(x='Rating', hue='Rating', data=ratings, palette="coolwarm", ax=ax, legend=False)

total = len(ratings)
for p in ax.patches:
    count = int(p.get_height())
    percentage = 100 * count / total
    ax.annotate(f'{count}\n({percentage:.1f}%)',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=10)

ax.set_title("Phân phối điểm đánh giá thuốc", fontsize=14)
ax.set_xlabel("Rating", fontsize=12)
ax.set_ylabel("Số lượng", fontsize=12)

path1 = "charts_viz/rating_distribution.png"
plt.savefig(path1, bbox_inches='tight')
plt.close(fig)

# 2. Heatmap thiếu dữ liệu
ratings_matrix = ratings.pivot(index='PatientID', columns='DrugID', values='Rating')
fig, ax = plt.subplots(figsize=(12, 6))
sns.heatmap(ratings_matrix.isnull(),
            cbar=False,
            cmap=sns.color_palette(["#e3f2fd", "#0d47a1"]),
            yticklabels=False,
            xticklabels=False,
            ax=ax)

ax.set_title("Ma trận thiếu dữ liệu", fontsize=14)
ax.set_xlabel("DrugID", fontsize=12)
ax.set_ylabel("PatientID", fontsize=12)

path2 = "charts_viz/missing_matrix.png"
plt.savefig(path2, bbox_inches='tight')
plt.close(fig)

# 3. Boxplot top thuốc
top_drugs = ratings['DrugID'].value_counts().head(10).index
top_ratings = ratings[ratings['DrugID'].isin(top_drugs)]

fig, ax = plt.subplots(figsize=(12, 6))
sns.boxplot(x='DrugID', y='Rating', hue='DrugID', data=top_ratings, palette='pastel', ax=ax, legend=False)
ax.set_title("Boxplot: 10 thuốc được đánh giá nhiều nhất", fontsize=14)
ax.set_xlabel("DrugID", fontsize=12)
ax.set_ylabel("Rating", fontsize=12)

path3 = "charts_viz/top_drug_boxplot.png"
plt.savefig(path3, bbox_inches='tight')
plt.close(fig)

# ---- Hiển thị bằng HTML ngang với ảnh to hơn ----
for path in [path1, path2, path3]:
    with open(path, "rb") as f:
        img_data = base64.b64encode(f.read()).decode("utf-8")
        tag = f'''
        <img src="data:image/png;base64,{img_data}"
             style="margin-right: 30px; border:1px solid #ccc; height: 450px; object-fit: contain; border-radius: 6px"/>
        '''
        image_tags.append(tag)

html_code = '<div style="display: flex; overflow-x: auto; padding: 10px 0;">' + "".join(image_tags) + '</div>'
display(HTML(html_code))

# TODO: Chia dữ liệu thành tập huấn luyện, kiểm tra và xác thực
from sklearn.model_selection import train_test_split

# Đảm bảo dữ liệu đầu vào có 3 cột cần thiết
assert set(['PatientID', 'DrugID', 'Rating']).issubset(ratings.columns), "Thiếu cột cần thiết"

# Bước 1: Chia thành tập train_val (80%) và test (20%)
train_val, test = train_test_split(ratings, test_size=0.2, random_state=42)

# Bước 2: Chia train_val tiếp thành train (64%) và validation (16%)
train, val = train_test_split(train_val, test_size=0.2, random_state=42)  # 0.2 * 0.8 = 16%

# Kiểm tra kích thước kết quả
print("✅ Chia dữ liệu thành công:")
print(f"  Số mẫu tập huấn luyện (train): {len(train)}")
print(f"  Số mẫu tập xác thực (validation): {len(val)}")
print(f"  Số mẫu tập kiểm tra (test): {len(test)}")

# Hiển thị một vài dòng đầu của từng tập để kiểm tra
print("\n🔍 Ví dụ dữ liệu huấn luyện:")
print(train.head())

# TODO: Lưu dữ liệu
from google.colab import files
import os
import pandas as pd
import zipfile

# Tạo thư mục output nếu chưa có
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

# Lưu dữ liệu
ratings.to_csv(f"{output_dir}/ratings_full.csv", index=False)
train.to_csv(f"{output_dir}/train.csv", index=False)
val.to_csv(f"{output_dir}/val.csv", index=False)
test.to_csv(f"{output_dir}/test.csv", index=False)


# Tạo file ZIP
zip_filename = "ratings_data.zip"
zip_path = os.path.join(output_dir, zip_filename)

with zipfile.ZipFile(zip_path, "w") as zipf:
    zipf.write(f"{output_dir}/ratings_full.csv", arcname="ratings_full.csv")
    zipf.write(f"{output_dir}/train.csv", arcname="train.csv")
    zipf.write(f"{output_dir}/val.csv", arcname="val.csv")
    zipf.write(f"{output_dir}/test.csv", arcname="test.csv")

# Tải file ZIP về máy
files.download(zip_path)

"""# CHẶNG 2: LỌC CỘNG TÁC DỰA TRÊN BỘ NHỚ"""

# TODO: Triển khai lọc cộng tác dựa trên bệnh nhân
# sim_options = {'name': 'pearson', 'user_based': True}
# user_based_cf = KNNBasic(k=30, sim_options=sim_options)
# user_based_cf.fit(trainset)
# predictions_user = user_based_cf.test(testset)
# accuracy.rmse(predictions_user)
from surprise import KNNBasic, accuracy
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split

# Tạo dataset từ ratings gốc
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['PatientID', 'DrugID', 'Rating']], reader)
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Thiết lập tùy chọn cho user-based CF
sim_options = {'name': 'pearson', 'user_based': True}

# Tạo mô hình KNN
user_based_cf = KNNBasic(k=30, sim_options=sim_options)
user_based_cf.fit(trainset)

# Dự đoán và đánh giá
predictions_user = user_based_cf.test(testset)
print("RMSE - User-based CF:")
accuracy.rmse(predictions_user)

# TODO: Triển khai lọc cộng tác dựa trên thuốc
# sim_options = {'name': 'pearson', 'user_based': False}
# item_based_cf = KNNBasic(k=30, sim_options=sim_options)
# item_based_cf.fit(trainset)
# predictions_item = item_based_cf.test(testset)
# accuracy.rmse(predictions_item)
# Thiết lập tùy chọn cho item-based CF
sim_options = {'name': 'pearson', 'user_based': False}

# Tạo mô hình KNN
item_based_cf = KNNBasic(k=30, sim_options=sim_options)
item_based_cf.fit(trainset)

# Dự đoán và đánh giá
predictions_item = item_based_cf.test(testset)
print("RMSE - Item-based CF:")
accuracy.rmse(predictions_item)

# TODO: Triển khai phân rã ma trận với SVD
# svd = SVD(n_factors=20, n_epochs=20, lr_all=0.005, reg_all=0.02)
# svd.fit(trainset)
# predictions_svd = svd.test(testset)
# accuracy.rmse(predictions_svd)
from surprise import SVD

# Khởi tạo mô hình SVD
svd = SVD(n_factors=20, n_epochs=20, lr_all=0.005, reg_all=0.02)
svd.fit(trainset)

# Dự đoán và đánh giá
predictions_svd = svd.test(testset)
print("RMSE - SVD:")
accuracy.rmse(predictions_svd)

# TODO: So sánh hiệu suất của các phương pháp
print("== So sánh RMSE ==")
rmse_user = accuracy.rmse(predictions_user, verbose=False)
rmse_item = accuracy.rmse(predictions_item, verbose=False)
rmse_svd = accuracy.rmse(predictions_svd, verbose=False)

print(f"User-Based CF: {rmse_user:.4f}")
print(f"Item-Based CF: {rmse_item:.4f}")
print(f"SVD: {rmse_svd:.4f}")

# TODO: Phân tích ảnh hưởng của các tham số
from surprise import KNNBasic, accuracy
from surprise.model_selection import train_test_split, KFold
from surprise import Dataset, Reader
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os
import base64
from IPython.display import HTML, display

# Thiết lập
sns.set(style="whitegrid")
os.makedirs("charts_viz", exist_ok=True)
image_tags = []

# Tạo dataset
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['PatientID', 'DrugID', 'Rating']], reader)
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# 1. Phân tích RMSE theo từng k
k_values = [10, 20, 30, 40, 50]
rmse_scores = []

for k in k_values:
    algo = KNNBasic(k=k, sim_options={'name': 'pearson', 'user_based': True})
    algo.fit(trainset)
    preds = algo.test(testset)
    rmse = accuracy.rmse(preds, verbose=False)
    rmse_scores.append(rmse)
    print(f"k = {k}, RMSE = {rmse:.4f}")

# Line plot
fig, ax = plt.subplots(figsize=(12, 6))
ax.plot(k_values, rmse_scores, marker='o', linestyle='-', color='green')
ax.set_title("Ảnh hưởng của k đến RMSE (Line plot)", fontsize=14)
ax.set_xlabel("k - Số hàng xóm", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)
ax.grid(True)

path1 = "charts_viz/rmse_line.png"
plt.savefig(path1, bbox_inches='tight')
plt.close(fig)

# Bar chart
fig, ax = plt.subplots(figsize=(12, 6))
sns.barplot(x=k_values, y=rmse_scores, hue=k_values, palette='viridis', ax=ax, legend=False)
ax.set_title("Ảnh hưởng của k đến RMSE (Bar chart)", fontsize=14)
ax.set_xlabel("k - Số hàng xóm", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)
ax.set_ylim(min(rmse_scores) - 0.05, max(rmse_scores) + 0.05)

path2 = "charts_viz/rmse_bar.png"
plt.savefig(path2, bbox_inches='tight')
plt.close(fig)

# Scatter plot
fig, ax = plt.subplots(figsize=(12, 6))
ax.scatter(k_values, rmse_scores, color='blue')
for i, rmse in enumerate(rmse_scores):
    ax.text(k_values[i], rmse + 0.005, f"{rmse:.3f}", ha='center')
ax.set_title("Ảnh hưởng của k đến RMSE (Scatter plot)", fontsize=14)
ax.set_xlabel("k - Số hàng xóm", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)
ax.grid(True)

path3 = "charts_viz/rmse_scatter.png"
plt.savefig(path3, bbox_inches='tight')
plt.close(fig)

# 2. Boxplot phân phối RMSE qua nhiều lần chia
rmse_dict = {k: [] for k in k_values}
kf = KFold(n_splits=3)

for k in k_values:
    for trainset_cv, testset_cv in kf.split(data):
        algo = KNNBasic(k=k, sim_options={'name': 'pearson', 'user_based': True})
        algo.fit(trainset_cv)
        preds = algo.test(testset_cv)
        rmse = accuracy.rmse(preds, verbose=False)
        rmse_dict[k].append(rmse)

df_rmse = pd.DataFrame([(k, val) for k, vals in rmse_dict.items() for val in vals],
                       columns=["k", "RMSE"])

fig, ax = plt.subplots(figsize=(12, 6))
sns.boxplot(x="k", y="RMSE", hue="k", data=df_rmse, palette="Set2", ax=ax, legend=False)
ax.set_title("Phân phối RMSE cho từng giá trị k (Boxplot)", fontsize=14)
ax.set_xlabel("k - Số hàng xóm", fontsize=12)
ax.set_ylabel("RMSE", fontsize=12)

path4 = "charts_viz/rmse_boxplot.png"
plt.savefig(path4, bbox_inches='tight')
plt.close(fig)

# 3. Hiển thị HTML ngang, ảnh lớn hơn
for path in [path1, path2, path3, path4]:
    with open(path, "rb") as f:
        img_data = base64.b64encode(f.read()).decode("utf-8")
        tag = f'''
        <img src="data:image/png;base64,{img_data}"
             style="margin-right: 30px; border:1px solid #ccc; height: 450px; object-fit: contain; border-radius: 6px"/>
        '''
        image_tags.append(tag)

html_code = '<div style="display: flex; overflow-x: auto; padding: 10px 0;">' + "".join(image_tags) + '</div>'
display(HTML(html_code))

# TODO: Phân tích kết quả
from collections import defaultdict
import pandas as pd
from IPython.display import HTML, display

# Hàm lấy top N dự đoán
def get_top_n(predictions, n=5):
    top_n = defaultdict(list)
    for uid, iid, true_r, est, _ in predictions:
        top_n[uid].append((iid, est))
    for uid in top_n:
        top_n[uid].sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = top_n[uid][:n]
    return top_n

# Lấy top 5 dự đoán cho mỗi bệnh nhân
top_n = get_top_n(predictions_user, n=5)

html_tables = []
modals = []  # popup modals

for uid, items in top_n.items():
    df = pd.DataFrame(items, columns=["💊 Mã thuốc", "⭐ Dự đoán"])
    df["⭐ Dự đoán"] = df["⭐ Dự đoán"].map(lambda x: f"{x:.2f}")

    # Bảng chính
    table_html = df.style.set_table_attributes('style="width:100%; border-collapse:collapse;"')\
        .set_table_styles([
            {'selector': 'th', 'props': [
                ('background-color', '#4f81bd'),
                ('color', 'white'),
                ('font-weight', 'bold'),
                ('font-size', '14px'),
                ('padding', '8px'),
                ('text-align', 'center'),
                ('border', '1px solid #ccc'),
                ('font-family', 'Roboto, sans-serif')
            ]},
            {'selector': 'td', 'props': [
                ('color', '#000000'),
                ('font-weight', '500'),
                ('text-align', 'center'),
                ('font-size', '13px'),
                ('padding', '6px'),
                ('border', '1px solid #ddd'),
                ('font-family', 'Roboto, sans-serif')
            ]}
        ]).hide(axis="index").to_html()

    # Thẻ nhỏ
    card_html = f"""
    <div onclick="document.getElementById('modal_{uid}').style.display='block'" style="
        flex: 1;
        max-width: 300px;
        background: #ffffff;
        border-radius: 12px;
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.08);
        padding: 20px;
        margin: 10px;
        cursor: pointer;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    " onmouseover="this.style.transform='scale(1.02)'; this.style.boxShadow='0 12px 25px rgba(0,0,0,0.15)'"
       onmouseout="this.style.transform='none'; this.style.boxShadow='0 8px 20px rgba(0,0,0,0.08)'">
        <h3 style="text-align: center; color: #2c3e50; font-size: 18px; margin-bottom: 12px; font-family: Roboto, sans-serif;">
            👤 Bệnh nhân {uid}
        </h3>
        {table_html}
    </div>
    """
    html_tables.append(card_html)

    # Modal popup
    modal_html = f"""
    <div id="modal_{uid}" style="
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        overflow: auto;
        background-color: rgba(0,0,0,0.5);
    ">
        <div style="
            background-color: #fff;
            margin: 10% auto;
            padding: 20px;
            border: 1px solid #888;
            width: 80%;
            max-width: 600px;
            border-radius: 10px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.3);
            font-family: Roboto, sans-serif;
        ">
            <span onclick="document.getElementById('modal_{uid}').style.display='none'" style="
                color: #aaa;
                float: right;
                font-size: 28px;
                font-weight: bold;
                cursor: pointer;
            ">&times;</span>
            <h2 style="text-align:center; color:#2c3e50;">👤 Bệnh nhân {uid}</h2>
            {table_html}
        </div>
    </div>
    """
    modals.append(modal_html)

# HTML tổng thể
final_html = f"""
<style>
@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');
</style>
<div style="
    display: flex;
    flex-wrap: wrap;
    justify-content: center;
    align-items: flex-start;
    gap: 20px;
    background: #f4f9ff;
    padding: 30px;
    border-radius: 15px;
    font-family: 'Roboto', sans-serif;
">
    {''.join(html_tables)}
</div>
{''.join(modals)}
"""

display(HTML(final_html))

"""# CHẶNG 3: LỌC CỘNG TÁC DỰA TRÊN MÔ HÌNH HỌC MÁY"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from mlxtend.frequent_patterns import apriori, association_rules
import pandas as pd
import numpy as np

# TODO: Kết hợp đặc trưng của bệnh nhân và thuốc
def combine_features(ratings_full):
    # Kết hợp đặc trưng bệnh nhân và thuốc
    features = ratings_full.drop(['PatientID', 'DrugID', 'Rating', 'Timestamp'], axis=1)
    ratings = ratings_full['Rating']

    # Hiển thị kích thước và vài dòng đầu tiên
    print(f"✅ Kích thước đặc trưng (features): {features.shape}")
    print("📋 Một số dòng đầu tiên của đặc trưng:")
    display(features.head())

    print("\n🎯 Một số nhãn (ratings) đầu tiên:")
    print(ratings.head())

    return features, ratings

# Gọi hàm (giả sử bạn có DataFrame `ratings_full` đã kết hợp đủ đặc trưng)
features, ratings = combine_features(ratings_full)

# TODO: Triển khai mô hình cây quyết định theo từng nhánh dựa vào dữ liệu
from sklearn.tree import DecisionTreeRegressor, export_text, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt

# Hàm phân nhóm tuổi
def group_age(age):
    if age <= 30:
        return "18-30"
    elif age <= 50:
        return "31-50"
    else:
        return "51+"

# Thêm cột nhóm tuổi và kiểm tra cột khu vực
ratings_full['AgeGroup'] = ratings_full['Age'].apply(group_age)

if 'Region' not in ratings_full.columns:
    ratings_full['Region'] = 'Unknown'

# Lặp qua từng tổ hợp của Gender, AgeGroup, Condition và Region để tạo mô hình cây quyết định riêng
for (gender, age_group, condition, region) in ratings_full[['Gender', 'AgeGroup', 'Condition', 'Region']].drop_duplicates().itertuples(index=False):
    print(f"\n========== Mô hình cho: Gender={gender}, AgeGroup={age_group}, Condition={condition}, Region={region} ==========")

    # Lọc dữ liệu theo tổ hợp điều kiện
    subset = ratings_full[(ratings_full['Gender'] == gender) &
                          (ratings_full['AgeGroup'] == age_group) &
                          (ratings_full['Condition'] == condition) &
                          (ratings_full['Region'] == region)]

    # Nếu tập con có quá ít dữ liệu, bỏ qua
    if len(subset) < 10:
        print("(Bỏ qua do dữ liệu không đủ)")
        continue

    # Tách features và target
    X = subset.drop(columns=['Rating', 'PatientID', 'DrugID', 'Timestamp', 'AgeGroup'])
    y = subset['Rating']

    # Áp dụng one-hot encoding
    X_encoded = pd.get_dummies(X)

    # Chia dữ liệu huấn luyện và kiểm tra
    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

    # Khởi tạo mô hình cây quyết định với độ sâu giới hạn
    dt_model = DecisionTreeRegressor(random_state=42, max_depth=3)
    dt_model.fit(X_train, y_train)

    # Dự đoán và đánh giá mô hình
    y_pred = dt_model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"Mean Squared Error (MSE): {mse:.2f}")
    print(f"R-squared (R2 Score): {r2:.2f}")

    # Xuất cây quyết định dạng văn bản
    tree_rules = export_text(dt_model, feature_names=list(X_encoded.columns))
    print(tree_rules)

    # Vẽ sơ đồ cây quyết định
    plt.figure(figsize=(20, 10))
    plot_tree(dt_model, feature_names=X_encoded.columns, filled=True, fontsize=12, rounded=True)
    plt.title(f"Decision Tree: Gender={gender}, AgeGroup={age_group}, Condition={condition}, Region={region} (max_depth=3)")
    plt.show()

# TODO: Triển khai rừng ngẫu nhiên
from sklearn.ensemble import RandomForestRegressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

print("📌 Kết quả dự đoán Random Forest (5 giá trị đầu tiên):")
print(rf_pred[:5])

# TODO: Triển khai XGBoost
from xgboost import XGBRegressor
xgb_model = XGBRegressor(n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)
xgb_pred = xgb_model.predict(X_test)

print("\n📌 Kết quả dự đoán XGBoost (5 giá trị đầu tiên):")
print(xgb_pred[:5])

#  TODO : So sánh hiệu suất của các phương pháp
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Hàm đánh giá mô hình
def evaluate_model(name, y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    print(f"\n🔎 Đánh giá mô hình {name}:")
    print(f"✅ MSE: {mse:.4f}")
    print(f"✅ MAE: {mae:.4f}")
    print(f"✅ R2 Score: {r2:.4f}")

    return {'MSE': mse, 'MAE': mae, 'R2': r2}

# Đánh giá hai mô hình
rf_metrics = evaluate_model("Random Forest", y_test, rf_pred)
xgb_metrics = evaluate_model("XGBoost", y_test, xgb_pred)

# ================================
# ✅ Tạo bảng tổng hợp bằng pandas
# ================================
metrics_df = pd.DataFrame({
    'Random Forest': rf_metrics,
    'XGBoost': xgb_metrics
}).T  # Transpose để mô hình là hàng

print("\n📊 Bảng so sánh hiệu suất các mô hình:")
display(metrics_df.style.background_gradient(cmap='YlGnBu'))

# ================================
# ✅ Vẽ biểu đồ cột so sánh hiệu suất
# ================================
models = ['Random Forest', 'XGBoost']
mse_values = [rf_metrics['MSE'], xgb_metrics['MSE']]
mae_values = [rf_metrics['MAE'], xgb_metrics['MAE']]
r2_values = [rf_metrics['R2'], xgb_metrics['R2']]

x = np.arange(len(models))
bar_width = 0.25

plt.figure(figsize=(10, 6))
plt.bar(x - bar_width, mse_values, width=bar_width, label='MSE', color='salmon')
plt.bar(x, mae_values, width=bar_width, label='MAE', color='skyblue')
plt.bar(x + bar_width, r2_values, width=bar_width, label='R2', color='limegreen')

plt.xticks(x, models)
plt.ylabel("Giá trị lỗi / R2")
plt.title("📈 So sánh hiệu suất các mô hình")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

#   TODO : Phân tích đặc trưng quan trọng
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

def plot_feature_importance(model, title, features, top_n=10):
    importance = model.feature_importances_
    indices = np.argsort(importance)[::-1][:top_n]

    sorted_features = [features[i] for i in indices]
    sorted_importance = importance[indices]

    plt.figure(figsize=(12, 6))
    sns.set_style("whitegrid")

    bars = plt.barh(range(top_n), sorted_importance[::-1],
                    color=sns.color_palette("viridis", top_n))

    plt.yticks(range(top_n), sorted_features[::-1], fontsize=12)
    plt.xlabel("Độ quan trọng", fontsize=13)
    plt.title(f"🌟 {title}", fontsize=16, weight='bold')

    # Thêm giá trị trên mỗi thanh
    for i, bar in enumerate(bars):
        plt.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,
                 f"{sorted_importance[::-1][i]:.3f}",
                 va='center', fontsize=11, color='black')

    plt.tight_layout()
    plt.show()

# ✅ Gọi hàm
feature_names = list(X_train.columns)
plot_feature_importance(rf_model, "Random Forest - Feature Importance", feature_names, top_n=min(10, len(feature_names)))

print(X.shape)
print(X_train.shape)
print(X.columns)
print(X_train.columns)

#  TODO : Triển khai luật kết hợp (Association Rules)
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import pandas as pd

# ✅ 1. Lấy các biến phân loại
df_categorical = df.select_dtypes(include=['object', 'category'])

# ✅ 2. Chuyển dữ liệu thành danh sách giao dịch
transactions = df_categorical.astype(str).values.tolist()

# ✅ 3. Mã hóa giao dịch
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_tf = pd.DataFrame(te_ary, columns=te.columns_)

# ✅ 4. Áp dụng Apriori và tạo luật
frequent_itemsets = apriori(df_tf, min_support=0.01, use_colnames=True)
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.6)

# ✅ 5. In Top 10 luật mạnh nhất
print("\n🔗 Top 10 luật kết hợp mạnh nhất (theo độ tin cậy):")
rules_sorted = rules.sort_values(by='confidence', ascending=False).head(10)
for idx, row in rules_sorted.iterrows():
    print(f"- Nếu có {set(row['antecedents'])} thì có khả năng {set(row['consequents'])} (Confidence = {row['confidence']:.2f})")

"""# CHẶNG 4: XÂY DỰNG HỆ THỐNG KHUYẾN NGHỊ PHƯƠNG PHÁP ĐIỀU TRỊ CHO BỆNH NHÂN TIỂU ĐƯỜNG"""

from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from sklearn.model_selection import train_test_split as sk_split
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def create_diabetes_data(n_patients=1000):
    np.random.seed(42)
    patient_ids = [f'P{i:04d}' for i in range(1, n_patients+1)]
    ages = np.random.normal(60, 12, n_patients).astype(int)
    ages = np.clip(ages, 30, 90)
    genders = np.random.choice(['Nam', 'Nữ'], size=n_patients)
    bmi = np.random.normal(28, 5, n_patients)
    bmi = np.clip(bmi, 18, 45)
    hba1c_initial = np.random.normal(8.5, 1.5, n_patients)
    hba1c_initial = np.clip(hba1c_initial, 6.5, 14)
    duration = np.random.gamma(shape=2, scale=5, size=n_patients)
    duration = np.clip(duration, 0, 30)
    complications = np.random.choice(['Không', 'Thận', 'Mắt', 'Thần kinh', 'Tim mạch', 'Nhiều biến chứng'],
                                    size=n_patients,
                                    p=[0.4, 0.1, 0.1, 0.1, 0.1, 0.2])
    patients = pd.DataFrame({
        'PatientID': patient_ids,
        'Age': ages,
        'Gender': genders,
        'BMI': bmi,
        'HbA1c_Initial': hba1c_initial,
        'Duration': duration,
        'Complications': complications
    })
    return patients

def create_treatment_data(n_treatments=20):
    np.random.seed(43)
    treatment_ids = [f'T{i:02d}' for i in range(1, n_treatments+1)]
    drug_classes = [
        'Metformin',
        'Sulfonylurea',
        'DPP-4 inhibitor',
        'SGLT-2 inhibitor',
        'GLP-1 agonist',
        'Insulin',
        'Metformin + Sulfonylurea',
        'Metformin + DPP-4 inhibitor',
        'Metformin + SGLT-2 inhibitor',
        'Metformin + GLP-1 agonist',
        'Metformin + Insulin',
        'Triple therapy',
        'Intensive insulin therapy'
    ]
    treatments = pd.DataFrame({
        'TreatmentID': treatment_ids,
        'DrugClass': np.random.choice(drug_classes, n_treatments, replace=True),
        'Intensity': np.random.choice(['Thấp', 'Trung bình', 'Cao'], n_treatments),
        'SideEffectRisk': np.random.choice(['Thấp', 'Trung bình', 'Cao'], n_treatments),
        'CostLevel': np.random.choice(['Thấp', 'Trung bình', 'Cao'], n_treatments)
    })
    return treatments

def create_treatment_results(patients, treatments, density=0.1):
    np.random.seed(44)
    n_patients = len(patients)
    n_treatments = len(treatments)
    n_results = int(n_patients * n_treatments * density)
    patient_indices = np.random.choice(n_patients, n_results)
    treatment_indices = np.random.choice(n_treatments, n_results)
    results = []
    for i in range(n_results):
        patient_idx = patient_indices[i]
        treatment_idx = treatment_indices[i]
        patient = patients.iloc[patient_idx]
        treatment = treatments.iloc[treatment_idx]
        effectiveness = 0
        if patient['Age'] > 70 and patient['Complications'] in ['Tim mạch', 'Nhiều biến chứng']:
            if 'DPP-4' in treatment['DrugClass']:
                effectiveness += 1
            if 'Sulfonylurea' in treatment['DrugClass'] or treatment['Intensity'] == 'Cao':
                effectiveness -= 1
        if patient['BMI'] > 30:
            if 'SGLT-2' in treatment['DrugClass'] or 'GLP-1' in treatment['DrugClass']:
                effectiveness += 1
            if 'Insulin' in treatment['DrugClass'] or 'Sulfonylurea' in treatment['DrugClass']:
                effectiveness -= 0.5
        if patient['Complications'] in ['Thận', 'Nhiều biến chứng']:
            if 'SGLT-2' in treatment['DrugClass']:
                effectiveness += 1
            if 'Metformin' in treatment['DrugClass'] and treatment['Intensity'] == 'Cao':
                effectiveness -= 1
        if patient['Duration'] < 5 and patient['HbA1c_Initial'] < 8:
            if 'Metformin' in treatment['DrugClass'] and '+' not in treatment['DrugClass']:
                effectiveness += 1
        if patient['Duration'] > 10 and patient['HbA1c_Initial'] > 9:
            if 'Insulin' in treatment['DrugClass'] or 'Triple' in treatment['DrugClass']:
                effectiveness += 1
            if '+' not in treatment['DrugClass'] and 'Insulin' not in treatment['DrugClass']:
                effectiveness -= 1
        effectiveness += np.random.normal(0, 0.5)
        effectiveness = np.clip(effectiveness + 3, 1, 5)
        hba1c_reduction = (effectiveness - 1) / 4 * 2
        hba1c_after = patient['HbA1c_Initial'] - hba1c_reduction
        if treatment['SideEffectRisk'] == 'Cao':
            side_effect_prob = 0.5
        elif treatment['SideEffectRisk'] == 'Trung bình':
            side_effect_prob = 0.3
        else:
            side_effect_prob = 0.1
        if patient['Age'] > 70:
            side_effect_prob += 0.1
        if patient['Complications'] in ['Nhiều biến chứng']:
            side_effect_prob += 0.1
        side_effect = np.random.choice(['Có', 'Không'], p=[side_effect_prob, 1-side_effect_prob])
        if treatment['CostLevel'] == 'Cao':
            adherence_prob = 0.7
        elif treatment['CostLevel'] == 'Trung bình':
            adherence_prob = 0.8
        else:
            adherence_prob = 0.9
        if patient['Age'] > 70:
            adherence_prob -= 0.1
        if 'Insulin' in treatment['DrugClass']:
            adherence_prob -= 0.1
        adherence = np.random.choice(['Tốt', 'Kém'], p=[adherence_prob, 1-adherence_prob])
        results.append({
            'PatientID': patient['PatientID'],
            'TreatmentID': treatment['TreatmentID'],
            'Effectiveness': effectiveness,
            'HbA1c_After': hba1c_after,
            'SideEffect': side_effect,
            'Adherence': adherence,
            'Timestamp': np.random.randint(1577836800, 1640995200)
        })
    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values('Timestamp').drop_duplicates(
        subset=['PatientID', 'TreatmentID'], keep='last'
    )
    return results_df

# TODO: Tạo dữ liệu
# patients = create_diabetes_data(1000)
# treatments = create_treatment_data(20)
# results = create_treatment_results(patients, treatments, density=0.1)
patients = create_patient_data(1000)
drugs = create_drug_data(200)
ratings = create_ratings_data(patients, drugs, density=0.05)

# Gộp dữ liệu bệnh nhân – thuốc – đánh giá
ratings_full = ratings.merge(patients, on='PatientID').merge(drugs, on='DrugID')

# HIỂN THỊ 10 DÒNG ĐẦU TIÊN
print("📌 Dữ liệu kết hợp giữa bệnh nhân, thuốc và đánh giá:")
ratings_full.head(10)

# TODO: Tiền xử lý dữ liệu
# 1. One-hot encoding các cột phân loại
categorical_cols = ['Gender', 'Condition', 'HistorySeverity', 'Type', 'Purpose', 'SideEffect', 'Contraindication']
df_encoded = pd.get_dummies(ratings_full, columns=categorical_cols)

# ✅ Hiển thị dữ liệu sau one-hot
print("🎯 Dữ liệu sau one-hot encoding (5 dòng đầu):")
display(df_encoded.head())

# 2. Lấy các đặc trưng lâm sàng để huấn luyện
feature_cols = [col for col in df_encoded.columns if col not in ['PatientID', 'DrugID', 'Rating', 'Timestamp']]
X = df_encoded[feature_cols]
y = df_encoded['Rating']

print(f"\n✅ Số lượng đặc trưng đầu vào (features): {X.shape[1]}")
print(f"✅ Tổng số mẫu (samples): {X.shape[0]}")

# ✅ Hiển thị một số đặc trưng đầu vào và đầu ra
print("\n🎯 Một số đặc trưng đầu vào:")
display(X.head())

print("\n🎯 Một số nhãn (ratings) tương ứng:")
print(y.head())

# 3. Chia dữ liệu
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\n📊 Tập huấn luyện: {X_train.shape[0]} mẫu")
print(f"📊 Tập kiểm tra: {X_test.shape[0]} mẫu")

# TODO: Triển khai lọc cộng tác dựa trên bệnh nhân
from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate

# 1. Chuẩn bị dữ liệu cho surprise
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['PatientID', 'DrugID', 'Rating']], reader)

# 2. Khởi tạo mô hình SVD
model_cf = SVD()

# 3. Đánh giá mô hình bằng cross-validation
print("🔍 Đang huấn luyện mô hình Collaborative Filtering (SVD)...\n")
results = cross_validate(model_cf, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)

# 4. Hiển thị kết quả chi tiết
import numpy as np
print("\n📊 Kết quả đánh giá mô hình SVD:")
metrics_summary = {}
for key, values in results.items():
    if 'test_' in key:
        mean_score = np.mean(values)
        metrics_summary[key] = values
        print(f"✅ {key}: {values} → Mean = {mean_score:.4f}")

# 5. Hiển thị bảng tham số mô hình
import pandas as pd
from IPython.display import display

params = {
    'n_factors': model_cf.n_factors,
    'n_epochs': model_cf.n_epochs,
    'biased': model_cf.biased,
}

# Bổ sung thêm các tham số khởi tạo thủ công
# (không thể lấy trực tiếp từ mô hình nên phải tự xác định)
params.update({
    'lr_all (default)': 0.005,
    'reg_all (default)': 0.02,
    'init_mean (default)': 0,
    'init_std_dev (default)': 0.1
})

import pandas as pd
params_df = pd.DataFrame(params.items(), columns=["Tham số", "Giá trị"])
from IPython.display import display
print("\n📋 Bảng tham số mô hình SVD:")
display(params_df)

# 6. Hiển thị biểu đồ các chỉ số đánh giá
import matplotlib.pyplot as plt

metric_labels = list(metrics_summary.keys())
metric_means = [np.mean(v) for v in metrics_summary.values()]

plt.figure(figsize=(6, 4))
bars = plt.bar(metric_labels, metric_means, color=['skyblue', 'salmon'])
plt.title('🎯 Trung bình các chỉ số đánh giá mô hình SVD')
plt.ylabel('Giá trị lỗi')
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f"{yval:.4f}", ha='center', va='bottom')
plt.ylim(0, max(metric_means) + 0.1)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# TODO: Triển khai XGBoost với đặc trưng lâm sàng
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

model_xgb = XGBRegressor()
model_xgb.fit(X_train, y_train)
y_pred = model_xgb.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

print(f'📊 Kết quả mô hình XGBoost:')
print(f'✅ RMSE: {rmse:.2f}')
print(f'✅ MAE: {mae:.2f}')

# TODO: Kết hợp hai phương pháp
# Dự đoán từ mô hình CF
trainset = data.build_full_trainset()
model_cf.fit(trainset)

# Lấy lại ID từ test set để kết hợp
test_df = df_encoded.iloc[X_test.index]
test_pairs = ratings.iloc[X_test.index][['PatientID', 'DrugID']].reset_index(drop=True)

cf_preds = []
for pid, did in zip(test_pairs['PatientID'], test_pairs['DrugID']):
    pred = model_cf.predict(pid, did).est
    cf_preds.append(pred)

# Kết hợp: Trung bình giữa CF và XGBoost
combined_preds = (np.array(cf_preds) + y_pred) / 2

# Tính RMSE (sửa lỗi squared)
rmse_combined = np.sqrt(mean_squared_error(y_test, combined_preds))

print(f'\n🤝 Kết hợp Collaborative Filtering + XGBoost:')
print(f'✅ RMSE tổng hợp: {rmse_combined:.2f}')

# TODO: Đánh giá hệ thống
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from IPython.display import display

# 1. Tạo bảng kết quả RMSE
results_df = pd.DataFrame({
    'Phương pháp': ['CF (SVD)', 'XGBoost', 'Kết hợp'],
    'RMSE': [1.15, rmse, rmse_combined]
})

# 2. Tìm phương pháp tốt nhất (RMSE nhỏ nhất)
min_rmse = results_df['RMSE'].min()

# 3. Hiển thị bảng với màu sắc và highlight giá trị tốt nhất
def highlight_min(s):
    is_min = s == s.min()
    return ['background-color: lightgreen; font-weight: bold' if v else '' for v in is_min]

print("📋 Bảng so sánh RMSE giữa các phương pháp khuyến nghị:")
styled_table = results_df.style\
    .format({"RMSE": "{:.3f}"})\
    .background_gradient(cmap='YlGnBu')\
    .apply(highlight_min, subset=['RMSE'])

display(styled_table)

# 4. Biểu đồ cột so sánh RMSE
plt.figure(figsize=(8, 5))
colors = ['skyblue', 'lightgreen', 'orchid']
sns.barplot(data=results_df, x='Phương pháp', y='RMSE', palette=colors)

# Ghi chú lên mỗi cột
for index, value in enumerate(results_df['RMSE']):
    plt.text(index, value + 0.05, f"{value:.3f}", ha='center', fontsize=10)

plt.title('🎯 So sánh độ chính xác (RMSE) giữa các phương pháp', fontsize=13)
plt.ylabel('RMSE (càng thấp càng tốt)')
plt.ylim(0, max(results_df['RMSE']) + 0.5)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Lưu bảng kết quả vào file Excel và tải xuống
output_filename = "ket_qua_so_sanh_rmse.xlsx"
results_df.to_excel(output_filename, index=False)
print(f"✅ Đã lưu bảng kết quả vào file '{output_filename}'")

# Tải file xuống máy cục bộ
try:
    files.download(output_filename)
    print(f"🎉 Đã tải xuống file '{output_filename}' thành công!")
except Exception as e:
    print(f"❌ Lỗi khi tải xuống file: {e}")

# TODO: Viết báo cáo
# ✅ Bước 1: Cài đặt thư viện PyMuPDF (tên gói: fitz)
!pip install pymupdf

# ✅ Bước 2: Tải file từ máy vào Colab
from google.colab import files
uploaded = files.upload()

# ✅ Bước 3: Đọc toàn bộ nội dung PDF
import fitz  # thư viện PyMuPDF

def read_pdf(filename):
    doc = fitz.open(filename)
    text = ''
    for page in doc:
        text += page.get_text()
    return text

# Thay bằng tên file PDF bạn đã tải lên
pdf_file = "Đinh_Lê_Quỳnh_Phương- 2211090031.pdf"
content = read_pdf(pdf_file)

# ✅ Bước 4: Hiển thị nội dung đầy đủ trong ô scroll
import ipywidgets as widgets
from IPython.display import display

textbox = widgets.Textarea(
    value=content,
    placeholder='Nội dung tiểu luận PDF',
    layout=widgets.Layout(width='100%', height='600px')
)
display(textbox)